{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models -- Amazon Fine Food Reviews\n",
    "## Kulikov Alex, gr. 397"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном домашнем задании вы будете решать задачу классификации отзывов.\n",
    "\n",
    "Шаги решения:\n",
    "\n",
    "1. Извлечение признаков: напишите код для создания TF-IDF матрицы из представленного корпуса отзывов\n",
    "2. Обучение моделей: напишите код для обучения SVM и логистической регрессии\n",
    "3. Кросс-валидация для подбора гиперпараметров: напишите код для оптимизации метрик обучения\n",
    "4. Участие в контесте на kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import random\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "pyplot.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "pyplot.rcParams['image.interpolation'] = 'nearest'\n",
    "pyplot.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pandas.options.display.max_colwidth = 0\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:90% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A super-cool trick for multithreading + visualization\n",
    "### https://habrahabr.ru/post/277919/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = size / 200     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{index} / ?'.format(index=index)\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{index} / {size}'.format(\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = str(index or '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jobs_manager():\n",
    "    from IPython.lib.backgroundjobs import BackgroundJobManager\n",
    "    from IPython.core.magic import register_line_magic\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    jobs = BackgroundJobManager()\n",
    "\n",
    "    @register_line_magic\n",
    "    def job(line):\n",
    "        ip = get_ipython()\n",
    "        jobs.new(line, ip.user_global_ns)\n",
    "\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kill_thread(thread):\n",
    "    import ctypes\n",
    "    \n",
    "    id = thread.ident\n",
    "    code = ctypes.pythonapi.PyThreadState_SetAsyncExc(\n",
    "        ctypes.c_long(id),\n",
    "        ctypes.py_object(SystemError)\n",
    "    )\n",
    "    if code == 0:\n",
    "        raise ValueError('invalid thread id')\n",
    "    elif code != 1:\n",
    "        ctypes.pythonapi.PyThreadState_SetAsyncExc(\n",
    "            ctypes.c_long(id),\n",
    "            ctypes.c_long(0)\n",
    "        )\n",
    "        raise SystemError('PyThreadState_SetAsyncExc failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chunks(sequence, count):\n",
    "    count = min(count, len(sequence))\n",
    "    chunks = [[] for _ in range(count)]\n",
    "    for index, item in enumerate(sequence):\n",
    "        chunks[index % count].append(item) \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo\n",
    "#### Just look at that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs = jobs_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import random\n",
    "\n",
    "def fetch_url(url):\n",
    "    sleep(random())\n",
    "    return url\n",
    "\n",
    "urls = range(100)\n",
    "urls2 = range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 0 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "%job [fetch_url(_) for _ in log_progress(urls, every=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kill_thread(jobs.running[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 2 in a separate thread.\n",
      "Starting job # 3 in a separate thread.\n",
      "Starting job # 4 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "for chunk in get_chunks(urls, 3):\n",
    "    %job [fetch_url(_) for _ in log_progress(chunk, every=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for job in jobs.running:\n",
    "    kill_thread(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But tqdm is still better and simpler to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знакомство с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352278, 2)\n",
      "                                                   Reviews_Summary  Prediction\n",
      "ID                                                                            \n",
      "230872  Babies love these                                           3         \n",
      "344823  Salmon Trout                                                0         \n",
      "211754  disappointment                                              1         \n",
      "259421  Doesn't taste like Cinnabon; tastes like Waffle Crisp       2         \n",
      "253418  Delicious San Daniele prosciutto and good customer service  3         \n",
      "                             Reviews_Summary  Prediction\n",
      "ID                                                      \n",
      "110273  We enjoy this coffee                  3         \n",
      "259187  Satisfied                             2         \n",
      "365859  quite good                            3         \n",
      "131937  Great yummy treat for my little ones  3         \n",
      "121963  Disappointed                          1         \n"
     ]
    }
   ],
   "source": [
    "data = pandas.read_csv(\"kaggle_data/train.csv\", index_col=0, na_values=\"NaN\")\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems that there aren't any missing values.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delicious!                                                       1627\n",
      "Delicious                                                        1529\n",
      "Yummy!                                                           1039\n",
      "Yummy                                                            826 \n",
      "Yum!                                                             733 \n",
      "Great product                                                    703 \n",
      "Excellent                                                        637 \n",
      "Great Product                                                    622 \n",
      "Love it!                                                         605 \n",
      "Great!                                                           527 \n",
      "Great                                                            486 \n",
      "Tasty                                                            422 \n",
      "Yum                                                              412 \n",
      "Excellent!                                                       376 \n",
      "Great Coffee                                                     372 \n",
      "Awesome                                                          362 \n",
      "Good stuff                                                       360 \n",
      "Disappointed                                                     349 \n",
      "Awesome!                                                         347 \n",
      "yummy                                                            337 \n",
      "Great product!                                                   325 \n",
      "Good Stuff                                                       317 \n",
      "Great coffee                                                     302 \n",
      "YUM!                                                             300 \n",
      "great product                                                    299 \n",
      "Love it                                                          297 \n",
      "delicious                                                        288 \n",
      "Very good                                                        288 \n",
      "The Best                                                         261 \n",
      "Amazing                                                          250 \n",
      "                                                                ...  \n",
      "Don't use for Tiramisu Recipe                                    1   \n",
      "good texture and good taste                                      1   \n",
      "not great ... but good for the price                             1   \n",
      "Benecol - works for me!                                          1   \n",
      "A great alternative to coffee                                    1   \n",
      "Perfect grain-free treats                                        1   \n",
      "10 stars!                                                        1   \n",
      "LOVE it, great for toddlers too                                  1   \n",
      "Super filling!                                                   1   \n",
      "Disappointing, low quality                                       1   \n",
      "False statement and inflated price!!!                            1   \n",
      "Get some!                                                        1   \n",
      "A sample got us hooked!                                          1   \n",
      "very low quality Tea                                             1   \n",
      "These saved my relationship with my cat!                         1   \n",
      "The Flames of Hell in a Bottle                                   1   \n",
      "Perfect healthy sugar replacement                                1   \n",
      "Got the wheat and the rye                                        1   \n",
      "Fantastic flavor and value!                                      1   \n",
      "It May Be Low Acid, but it Still Gave Me Heartburn               1   \n",
      "Horrid!=( Actually....zero stars.                                1   \n",
      "Incredible Mango flavor                                          1   \n",
      "AMAZING COFFEE!!                                                 1   \n",
      "Remember biting the top and pretending to drink the cola out?    1   \n",
      "Disappointed, not the classic flavor                             1   \n",
      "simply addicting delicous.                                       1   \n",
      "THE best gluten-free cookie!                                     1   \n",
      "Gritty and Gross                                                 1   \n",
      "i like it ICED!!!!                                               1   \n",
      "ST. DALFOUR Golden Peach is Delicious                            1   \n",
      "Name: Reviews_Summary, dtype: int64\n",
      "3    243136\n",
      "2    53979 \n",
      "0    35097 \n",
      "1    20066 \n",
      "Name: Prediction, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.Reviews_Summary.value_counts()) # no NaN\n",
    "# print(data.Reviews_Summary.value_counts()[\"NaN\"]) # -- KeyError\n",
    "print(data.Prediction.value_counts()) # no NaN\n",
    "# print(data.Prediction.value_counts()[\"NaN\"]) # -- KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = data[\"Reviews_Summary\"].values[:1000]\n",
    "score = data[\"Prediction\"].values[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 1 2 3 2 3 2 2 3]\n",
      "['Babies love these' 'Salmon Trout' 'disappointment'\n",
      " \"Doesn't taste like Cinnabon; tastes like Waffle Crisp\"\n",
      " 'Delicious San Daniele prosciutto and good customer service'\n",
      " 'My Dog Loves Them' \"My husband's new favorite coffee.\"\n",
      " 'Good Job, Betty Crocker' 'Good chips, more cheese'\n",
      " \"Nature's Hallow Sugar Free Jam\"]\n"
     ]
    }
   ],
   "source": [
    "print(score[:10])\n",
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, каждый объект представляет собой отзыв о продукте и оценку по шкале от 0 до 3. Выдвинем гипотезу, что слова, используемые в написании отзыва коррелируют с оценкой, которая была поставлена. Поставим задачу - предсказать оценку, по тексту отзыва."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Извлечение признаков - 10 Баллов\n",
    " \n",
    "\n",
    "1. Для решения задачи классификации необходимо преобразовать каждый отзыв (документ) в вектор. Размерность данного вектора будет равна количеству слов используемых в корпусе (все документы). Каждая координата соответствует слову, значение в координает равно количеству раз, слово используется в документе. \n",
    "\n",
    "Для решения данной задачи вам необходимо написать код, который преобразовывает матрицу документов в численную матрицу.\n",
    "\n",
    "Дополнительная информация для решения задачи:\n",
    "\n",
    "- Подробнее про векторное представление документов: http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "- Используйте данный трансформер: http://scikit-learn.org/stable/modules/feature_extraction.html#common-vectorizer-usage\n",
    "- Подробнее про разреженные матрицы: http://docs.scipy.org/doc/scipy-0.14.0/reference/sparse.html\n",
    "- Hashing trick: https://en.wikipedia.org/wiki/Feature_hashing\n",
    "\n",
    "Используйте n_features = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 79)\t1\n",
      "  (0, 666)\t1\n",
      "  (0, 1115)\t1\n",
      "  (1, 938)\t1\n",
      "  (1, 1150)\t1\n",
      "  (2, 318)\t1\n",
      "  (3, 330)\t1\n",
      "  (3, 1094)\t1\n",
      "  (3, 648)\t2\n",
      "  (3, 220)\t1\n",
      "  (3, 1096)\t1\n",
      "  (3, 1196)\t1\n",
      "  (3, 269)\t1\n",
      "  (4, 301)\t1\n",
      "  (4, 943)\t1\n",
      "  (4, 288)\t1\n",
      "  (4, 880)\t1\n",
      "  (4, 50)\t1\n",
      "  (4, 489)\t1\n",
      "  (4, 282)\t1\n",
      "  (4, 969)\t1\n",
      "  (5, 744)\t1\n",
      "  (5, 331)\t1\n",
      "  (5, 672)\t1\n",
      "  (5, 1114)\t1\n",
      "  :\t:\n",
      "  (995, 437)\t1\n",
      "  (996, 672)\t1\n",
      "  (996, 153)\t1\n",
      "  (996, 440)\t1\n",
      "  (996, 1075)\t1\n",
      "  (996, 471)\t1\n",
      "  (996, 1225)\t1\n",
      "  (996, 458)\t1\n",
      "  (996, 1033)\t1\n",
      "  (996, 1021)\t1\n",
      "  (996, 486)\t1\n",
      "  (997, 744)\t1\n",
      "  (997, 331)\t1\n",
      "  (997, 592)\t1\n",
      "  (997, 1118)\t1\n",
      "  (997, 788)\t1\n",
      "  (997, 1215)\t1\n",
      "  (997, 626)\t1\n",
      "  (997, 649)\t1\n",
      "  (998, 503)\t1\n",
      "  (998, 1133)\t1\n",
      "  (998, 41)\t1\n",
      "  (998, 450)\t1\n",
      "  (999, 489)\t1\n",
      "  (999, 232)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "\n",
    "corpus_vect = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(corpus_vect)\n",
    "\n",
    "mean_matrix_vect = corpus_vect.mean(axis = 1)\n",
    "\n",
    "# print(vectorizer.get_feature_names())\n",
    "# print(corpus_vect.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "  (0, 1134)\t0.57735026919\n",
      "  (0, 2170)\t0.57735026919\n",
      "  (0, 2201)\t-0.57735026919\n",
      "  (1, 1353)\t-0.707106781187\n",
      "  (1, 1857)\t-0.707106781187\n",
      "  (2, 1544)\t1.0\n",
      "  (3, 1465)\t-0.316227766017\n",
      "  (3, 1473)\t-0.316227766017\n",
      "  (3, 1480)\t-0.316227766017\n",
      "  (3, 1534)\t-0.316227766017\n",
      "  (3, 1706)\t0.316227766017\n",
      "  (3, 1855)\t-0.632455532034\n",
      "  (3, 2437)\t0.316227766017\n",
      "  (4, 72)\t0.353553390593\n",
      "  (4, 442)\t-0.353553390593\n",
      "  (4, 448)\t-0.353553390593\n",
      "  (4, 845)\t-0.353553390593\n",
      "  (4, 1729)\t0.353553390593\n",
      "  (4, 2369)\t0.353553390593\n",
      "  (4, 2381)\t-0.353553390593\n",
      "  (4, 2860)\t-0.353553390593\n",
      "  (5, 93)\t-0.5\n",
      "  (5, 719)\t-0.5\n",
      "  (5, 1490)\t0.5\n",
      "  (5, 1591)\t0.5\n",
      "  :\t:\n",
      "  (995, 2704)\t-0.4472135955\n",
      "  (996, 49)\t-0.316227766017\n",
      "  (996, 275)\t0.316227766017\n",
      "  (996, 861)\t0.316227766017\n",
      "  (996, 985)\t-0.316227766017\n",
      "  (996, 1092)\t-0.316227766017\n",
      "  (996, 1212)\t0.316227766017\n",
      "  (996, 1563)\t-0.316227766017\n",
      "  (996, 1591)\t0.316227766017\n",
      "  (996, 2344)\t0.316227766017\n",
      "  (996, 2462)\t0.316227766017\n",
      "  (997, 93)\t-0.353553390593\n",
      "  (997, 897)\t-0.353553390593\n",
      "  (997, 918)\t0.353553390593\n",
      "  (997, 1124)\t-0.353553390593\n",
      "  (997, 1490)\t0.353553390593\n",
      "  (997, 2201)\t0.353553390593\n",
      "  (997, 2531)\t-0.353553390593\n",
      "  (997, 2763)\t-0.353553390593\n",
      "  (998, 691)\t0.5\n",
      "  (998, 1000)\t-0.5\n",
      "  (998, 2027)\t0.5\n",
      "  (998, 2388)\t0.5\n",
      "  (999, 1729)\t0.707106781187\n",
      "  (999, 2704)\t-0.707106781187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vectorizer = HashingVectorizer(n_features=3000)\n",
    "print(type(corpus))\n",
    "\n",
    "corpus_hashed = hash_vectorizer.transform(corpus)\n",
    "\n",
    "print(corpus_hashed)\n",
    "\n",
    "mean_matrix_hash = corpus_hashed.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.00019245],\n",
       "        [-0.0004714 ],\n",
       "        [ 0.00033333],\n",
       "        [-0.00042164],\n",
       "        [-0.0002357 ],\n",
       "        [ 0.        ],\n",
       "        [-0.00014907],\n",
       "        [ 0.00066667],\n",
       "        [ 0.        ],\n",
       "        [ 0.00044721]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_matrix_hash[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для учета важности редких, но показательных слов (термов), используется схема взвешивания TF-IDF. Напишите код, принимающий на вход разреженную матрицу векторного представления документов и возвращающий разреженную матрицу документов, частоты термов которых взвешенны по TF-IDF.\n",
    "\n",
    "Дополнительная информация для решения задачи:\n",
    "\n",
    "- Подробнее про TF-IDF: https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "- Используйте трансформер: http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2201)\t-0.390666501164\n",
      "  (0, 2170)\t0.779067464351\n",
      "  (0, 1134)\t0.490340260287\n",
      "  (1, 1857)\t-0.707106781187\n",
      "  (1, 1353)\t-0.707106781187\n",
      "  (2, 1544)\t1.0\n",
      "  (3, 2437)\t0.400179329608\n",
      "  (3, 1855)\t-0.511667069701\n",
      "  (3, 1706)\t0.251870403554\n",
      "  (3, 1534)\t-0.281490746435\n",
      "  (3, 1480)\t-0.400179329608\n",
      "  (3, 1473)\t-0.400179329608\n",
      "  (3, 1465)\t-0.339250028345\n",
      "  (4, 2860)\t-0.398862124748\n",
      "  (4, 2381)\t-0.42260974453\n",
      "  (4, 2369)\t0.241570983252\n",
      "  (4, 1729)\t0.196491295799\n",
      "  (4, 845)\t-0.221485108061\n",
      "  (4, 448)\t-0.398862124748\n",
      "  (4, 442)\t-0.42260974453\n",
      "  (4, 72)\t0.42260974453\n",
      "  (5, 1591)\t0.561683898009\n",
      "  (5, 1490)\t0.41152000634\n",
      "  (5, 719)\t-0.523493979178\n",
      "  (5, 93)\t-0.491036186919\n",
      "  :\t:\n",
      "  (995, 179)\t-0.436247113522\n",
      "  (996, 2462)\t0.223607164312\n",
      "  (996, 2344)\t0.37541247004\n",
      "  (996, 1591)\t0.286718110855\n",
      "  (996, 1563)\t-0.184805274749\n",
      "  (996, 1212)\t0.327739843415\n",
      "  (996, 1092)\t-0.327739843415\n",
      "  (996, 985)\t-0.339349520165\n",
      "  (996, 861)\t0.354316996698\n",
      "  (996, 275)\t0.310233920079\n",
      "  (996, 49)\t-0.37541247004\n",
      "  (997, 2763)\t-0.420486443733\n",
      "  (997, 2531)\t-0.378820253791\n",
      "  (997, 2201)\t0.248724097697\n",
      "  (997, 1490)\t0.277544209108\n",
      "  (997, 1124)\t-0.367336841689\n",
      "  (997, 918)\t0.277544209108\n",
      "  (997, 897)\t-0.468133855274\n",
      "  (997, 93)\t-0.33117284225\n",
      "  (998, 2388)\t0.28699434447\n",
      "  (998, 2027)\t0.629513686819\n",
      "  (998, 1000)\t-0.602921027075\n",
      "  (998, 691)\t0.397282015024\n",
      "  (999, 2704)\t-0.765929143778\n",
      "  (999, 1729)\t0.642924993067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "TFIDFtransformer = TfidfTransformer()\n",
    "\n",
    "corpus_TFIDF = TFIDFtransformer.fit_transform(corpus_hashed)\n",
    "\n",
    "print(corpus_TFIDF)\n",
    "corpus_TFIDF\n",
    "\n",
    "\n",
    "mean_matrix_TFIDF = corpus_TFIDF.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00236035]\n",
      " [ 0.00157356]\n",
      " [ 0.00078678]\n",
      " [ 0.00629426]\n",
      " [ 0.00629426]\n",
      " [ 0.00314713]\n",
      " [ 0.00393391]\n",
      " [ 0.00314713]\n",
      " [ 0.00314713]\n",
      " [ 0.00393391]]\n",
      "[[ 0.00019245]\n",
      " [-0.0004714 ]\n",
      " [ 0.00033333]\n",
      " [-0.00042164]\n",
      " [-0.0002357 ]\n",
      " [ 0.        ]\n",
      " [-0.00014907]\n",
      " [ 0.00066667]\n",
      " [ 0.        ]\n",
      " [ 0.00044721]]\n",
      "[[  2.92913741e-04]\n",
      " [ -4.71404521e-04]\n",
      " [  3.33333333e-04]\n",
      " [ -4.26905590e-04]\n",
      " [ -3.34585608e-04]\n",
      " [ -1.37754206e-05]\n",
      " [ -1.31798867e-04]\n",
      " [  6.44775804e-04]\n",
      " [ -7.92367694e-05]\n",
      " [  4.08042424e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(mean_matrix_vect[:10])\n",
    "print(mean_matrix_hash[:10])\n",
    "print(mean_matrix_TFIDF[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем csc матрицу в numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(1000, 3000)\n"
     ]
    }
   ],
   "source": [
    "corpus_np = corpus_TFIDF.toarray()\n",
    "\n",
    "print(corpus_np)\n",
    "print(corpus_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Код для SVM и логистической регресии - 40 Баллов\n",
    "\n",
    "После того, как вы получили матрицу признаков, вам необходимо реализовать алгоритм обучения SVM и логистической регрессии. Обе модели являются линейными и отличаются функциями потерь. Для решения оптимизационных задач в обеих моделей будет использоваться стохастический градиентный спуск.\n",
    "\n",
    "Дополнительная информация для решения задачи:\n",
    "\n",
    "- Линейные модели: http://cs231n.github.io/linear-classify/\n",
    "- SGD: http://cs231n.github.io/optimization-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с SVM стартовый код находится в файле cs231n/classifiers/linear_svm.py вашей задачей является реализация подсчета функции потерь для SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте обучающую выборку на 2 части train и test\n",
    "\n",
    "Дополнительная информация для решения задачи:\n",
    "- Используйте трансформер: http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html#sklearn.cross_validation.train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(corpus_np, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 3000)\n",
      "(250, 3000)\n",
      "(750,)\n",
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Транспонируем матрицы с данными, т.к. так будет проще реализовать код SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.transpose()\n",
    "X_test = X_test.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем подвыборки из обучающей выборки, для быстрой проверки кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_sample = X_train[:, 0:1000]\n",
    "y_train_sample = y_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 750)\n",
      "(750,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sample.shape)\n",
    "print(y_train_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем чему равен градиент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.000200\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers.linear_svm import svm_loss_naive\n",
    "import time\n",
    "\n",
    "# generate a random SVM weight matrix of small numbers\n",
    "W = numpy.random.randn(4, X_train_sample.shape[0]) * 0.01 \n",
    "loss, grad = svm_loss_naive(W, X_train_sample, y_train_sample, 0.00001)\n",
    "print 'loss: %f' % (loss, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиент равен 0, т.к. код который должен его считать отсутствует. Реализуйте наивную версию и проверьте результат с помощью численного метода расчета. Градиенты должны почти совпадать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000800 analytic: 0.000800, relative error: 7.134922e-09\n"
     ]
    }
   ],
   "source": [
    "# Once you've implemented the gradient, recompute it with the code below\n",
    "# and gradient check it with the function we provided for you\n",
    "\n",
    "# Compute the loss and its gradient at W.\n",
    "loss, grad = svm_loss_naive(W, X_train_sample, y_train_sample, 0.0)\n",
    "\n",
    "# Numerically compute the gradient along several randomly chosen dimensions, and\n",
    "# compare them with your analytically computed gradient. The numbers should match\n",
    "# almost exactly along all dimensions.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: svm_loss_naive(w, X_train_sample, y_train_sample, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуйте векторизованную версию расчета фунции потерь - svm_loss_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive loss: 3.000200e+00 computed in 0.039408s\n",
      "Vectorized loss: 3.000200e+00 computed in 0.022170s\n",
      "difference: -0.000000\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "loss_naive, grad_naive = svm_loss_naive(W, X_train_sample, y_train_sample, 0.00001)\n",
    "toc = time.time()\n",
    "print 'Naive loss: %e computed in %fs' % (loss_naive, toc - tic)\n",
    "\n",
    "from cs231n.classifiers.linear_svm import svm_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, _ = svm_loss_vectorized(W, X_train_sample, y_train_sample, 0.00001)\n",
    "toc = time.time()\n",
    "print 'Vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic)\n",
    "\n",
    "# The losses should match but your vectorized implementation should be much faster.\n",
    "print 'difference: %f' % (loss_naive - loss_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Завершите реализацию SVM, реализуйте векторизированную версию расчета градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive loss and gradient: computed in 0.034995s\n",
      "Vectorized loss and gradient: computed in 0.022172s\n",
      "difference: 0.000011\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "_, grad_naive = svm_loss_naive(W, X_train_sample, y_train_sample, 0.00001)\n",
    "toc = time.time()\n",
    "print 'Naive loss and gradient: computed in %fs' % (toc - tic)\n",
    "\n",
    "tic = time.time()\n",
    "_, grad_vectorized = svm_loss_vectorized(W, X_train_sample, y_train_sample, 0.00001)\n",
    "toc = time.time()\n",
    "print 'Vectorized loss and gradient: computed in %fs' % (toc - tic)\n",
    "\n",
    "# The loss is a single number, so it is easy to compare the values computed\n",
    "# by the two implementations. The gradient on the other hand is a matrix, so\n",
    "# we use the Frobenius norm to compare them.\n",
    "difference = numpy.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print 'difference: %f' % difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 500: loss 2.999926\n",
      "iteration 100 / 500: loss 2.498815\n",
      "iteration 200 / 500: loss 2.075648\n",
      "iteration 300 / 500: loss 1.858928\n",
      "iteration 400 / 500: loss 1.731245\n",
      "That took 410.631081s\n",
      "Current loss is 1.654567\n"
     ]
    }
   ],
   "source": [
    "# Now implement SGD in LinearSVM.train() function and run it with the code below\n",
    "from cs231n.classifiers import LinearSVM\n",
    "svm = LinearSVM()\n",
    "tic = time.time()\n",
    "loss_hist = svm.train(X_train, y_train, learning_rate=5e-2, reg=0.01,\n",
    "                      num_iters=500, verbose=True, batch_size=20000)\n",
    "\n",
    "toc = time.time()\n",
    "print 'That took %fs' % (toc - tic)\n",
    "print 'Current loss is %f' % loss_hist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f1bc9c10750>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAHuCAYAAAAr7vARAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XeYldW1gPF3UwQVxSACCoqIooiCig3rgBq7Eo3GGjWJ\nJXotMTGa6I0Yk6ixxRILxp7YOzaubeyKjWIBFLvYO1IU2PePBQFx0GFmznznzLy/5znPnPLNOetk\nEl3Ze6+1Us4ZSZIklY8WRQcgSZKkbzNBkyRJKjMmaJIkSWXGBE2SJKnMmKBJkiSVGRM0SZKkMlPS\nBC2l1Cal9GRK6bmU0piU0vE1XLNQSumalNLLKaXHU0rLlTImSZKkclfSBC3nPA0YmHNeE1gD2Dql\ntO48l/0S+CTnvBLwD+DvpYxJkiSp3JV8izPnPHnW3TZAK2Dezrg7ApfPun8DsFmpY5IkSSpnJU/Q\nUkotUkrPAe8B9+Scn5rnkq7AWwA55xnAZymlDqWOS5IkqVy1KvUH5JxnAmumlBYHbkkprZpzfnGu\nS9I8v5L47iobKSVnUkmSpIqRc543x6m1RqvizDl/AVQDW83z0lvAsgAppZbA4jnnT2t6j9/+NpOz\nt0q8HX/88YXH4M2/XXO8+fer7Jt/v8q91Vepqzg7ppTaz7q/MLA5MHaey4YB+8y6vwtw//ze7+qr\n4cEHSxGpJElS+Sj1CtrSwAMppZHAk8DwnPOdKaUTUkrbzbrmYqBjSull4AjgmPm92dChsM8+8MUX\nJY5akiSpQCU9g5ZzHgOsVcPzx891fxqwa23eb9tt4dZb4Ygj4JJLGi5OlV5VVVXRIaiO/NtVNv9+\nlc2/X/OVGmKftDGklHLOmS+/hDXWgDPOgB13LDoqSZKk70opketRJFBxCRrAI4/ALrvAqFHQqVPB\ngUmSJM2jWSZoAEcfDePHw003Qarz15ckSWp49U3QKnZY+p//DBMmwBVXFB2JJElSw6rYFTSILc7N\nN4enn4bu3QsKTJIkaR7NdgUNoF8/+O1vYd99YebMoqORJElqGBWdoAEcdRR8/TWcdVbRkUiSJDWM\nit7inG3CBFhvPXjoIVh11UYOTJIkaR7Neotztp494a9/hb33hm++KToaSZKk+mkSCRrAAQdA585w\n4olFRyJJklQ/TWKLc7Z334U114RbboH112+kwCRJkubhFudcll4a/vlP2GsvmDSp6GgkSZLqpkmt\noM22776w0EIwdGhpY5IkSapJsx319H2++AJWXx0uuQQ226zEgUmSJM3DLc4aLL44nHceHHigW52S\nJKnyNMkVtNn23x8+/hhuuAFaNMlUVJIklSNX0L7HuedGZec55xQdiSRJUu016RU0gPHjYYMN4Ikn\nYMUVSxCYJEnSPFxB+wG9esEf/wi//KUD1SVJUmVo8gkawOGHxwioM88sOhJJkqQf1uS3OGd7/fWY\nLnDVVTBoUMPFJUmSNC+3OGtp+eXh4ovh1792oLokSSpvzSZBA9hmG+jWDS66qOhIJEmS5q9V0QE0\nppTgH/+I6QLLLx8JmyRJUrlpNmfQ5vb447DDDjBuHHTo0CBvKUmS9F/O4qyjgw6CRReF009vsLeU\nJEkCTNDq7L33YI014NJLYeutG+xtJUmSTNDq47HHYMcd4emnoXv3Bn1rSZLUjJmg1dOf/wwjR8JN\nNzX4W0uSpGbKPmj19Pvfw+jRcNddRUciSZIUmn2C1rYtnHMOHHYYTJ1adDSSJEkmaEAUCay2Gpx2\nWtGRSJIkeQbtv954A/r3hxEjYIUVSvYxkiSpGfAMWgPp3h2GDIFtt4WPPio6GkmS1Jy5gjaPo46K\nqs7hw6GF6askSaoDV9Aa2EknwZQpcMYZRUciSZKaK1fQavDGG7DOOtF6o3//RvlISZLUhLiCVgLd\nu0frjd13h0mTio5GkiQ1N66gfY9f/AJmzox5nanOObAkSWpuXEErobPPjjmd559fdCSSJKk5cQXt\nB0yYAOuvD/fcA2us0egfL0mSKpAraCXWsyecfjrss4+joCRJUuNwBa0Wco6CgbZtPY8mSZJ+mCto\njSAluPjiGAN1991FRyNJkpo6E7RaWnRROOYYOPPMoiORJElNnVucC+Drr2H55eHWW6ORrSRJUk3c\n4mxECy0UrTcGD4ZXXy06GkmS1FS1KjqASvPTn8LEiZGkPf54bH1KkiQ1JLc46yBn2G+/uH/ZZYWG\nIkmSypBbnAVICc49Fx55BG6+uehoJElSU+MKWj08/jj85CcwciR06VJ0NJIkqVzUdwXNBK2ejj0W\nXn4Zrruu6EgkSVK5MEEr2FdfQbdu8Pzz0LVr0dFIkqRy4Bm0gi26KOyyC1x+edGRSJKkpsI2Gw1g\n//3hxz+O3mgXXggtWxYdkSRJqmQlXUFLKXVLKd2fUnoxpTQmpXRYDdcsnlK6LaU0ctY1+5YyplJY\nZ52Y0/n003DPPUVHI0mSKl1Jz6CllLoAXXLOI1NK7YBngB1zzmPnuuYPwOI55z+klDoC44DOOefp\n87xXWZ5Bm9sFF8B998H11xcdiSRJKlJZn0HLOb+Xcx456/4k4CVg3qP0GVhs1v3FgI/nTc4qxW67\nwb33wnHHRfGAJElSXTRakUBKaXlgDeDJeV46F1g1pTQRGAUc3lgxNbQlloDqanjiiWhkK0mSVBeN\nUiQwa3vzBuDwWStpc9sSeC7nPCil1BO4J6XUt4brGDJkyH/vV1VVUVVVVbqg66hfPzjjDNh6azji\nCGjTpuiIJElSqVVXV1NdXd1g71fyPmgppVbA7cBdOeezanj9duCknPOjsx7fBxydc356nuvK/gza\n3LbbDpZfHs4+G1rYzESSpGalrM+gzXIJ8GJNydksbwCbA6SUOgO9gFcbIa6S+ve/YwTU3/9edCSS\nJKnSlLqKc0PgIWAMUQyQgT8C3YGccx6aUloauAxYetavnZRzvrqG96qoFTSA556DwYOjP5q90SRJ\naj4c9VTm1l03qjp32KHoSCRJUmOphC3OZu3YY2HffeGgg4qORJIkVQoTtBLbcUd46y24/34YNqzo\naCRJUiVwi7ORVFfD9tvD2mtHspbqvOgpSZLKnVucFaKqCj75BN5+G0aPLjoaSZJUzkzQGlHr1rDN\nNnDHHUVHIkmSypkJWiPbdlsTNEmS9P1M0BrZJpvAyy/HrM4KPlInSZJKqFFmcWqOtm3h0UejujNn\nOPTQoiOSJEnlxirOgkyYAAMGwO23RzNbSZLUdFjFWaF69oxtzn32gSlTio5GkiSVE1fQCvazn8Gy\ny8JppxUdiSRJaijO4qxwH30EffvCddfBRhsVHY0kSWoIbnFWuI4d4bzzYL/94Kuvio5GkiSVA1fQ\nysTee8NSS8EZZxQdiSRJqi+3OJuIDz6A3r3h6aehR4+io5EkSfXhFmcT0alT9EQ74ACYOLHoaCRJ\nUpFM0MrIMcdA//6wzjrwxRdFRyNJkoriFmcZ2ndf6NIFTj656EgkSVJdeAatCZo4EVZfHUaMiIa2\nkiSpsngGrQlaZhn43e/iJkmSmh9X0MrU1Kkxo3OtteDCC6FNm6IjkiRJteUKWhPVti08/ji8+65j\noCRJam5cQStzr70WVZ3PPgvLLVd0NJIkqTZcQWvievSAo4+GwYNh0qSio5EkSY3BFbQKkHOMglp2\nWTjppKKjkSRJP8Q2G83E+PGw8cbw5psWDEiSVO7c4mwmevWCfv3g8svho4+igECSJDVNrqBVkKef\nhh13hGnToGXLqPBsYYotSVLZcQWtGVl7bRg1Ch5+GDp2jIRNkiQ1PSZoFaZjR+jdG7bbDm6/veho\nJElSKZigVajttoMbb4Svvy46EkmS1NA8g1ahZs6EnXeGhRaCa66BVOddbkmS1NA8g9ZMtWgBV18N\n48bBddcVHY0kSWpIrqBVuIceiia2zz8Piy1WdDSSJAlsVCvgoINg4kS4+eZovyFJkorlFqc4+2z4\n4IPY8pQkSZXPBK0JWGghOOYYOO+8oiORJEkNwQStidhuO3j7bXj22aIjkSRJ9WWC1kS0agW/+Q0M\nGVJ0JJIkqb4sEmhCpk6FlVeG3/0OfvYz6NSp6IgkSWqeLBLQf7VtC1dcAf/3f7D55k4ZkCSpUrmC\n1gTlDDvsAJ07wwknQNeuRUckSVLz4gqaviMl+Ne/YtrAuuvCtGlFRyRJkhaECVoT1bkzDB0KffrE\nrE5JklQ5TNCauCOOgL//HT75pOhIJElSbZmgNXFbbRW3tdaCSZOKjkaSJNWGCVoT16IFnH56tN8Y\nPrzoaCRJUm2YoDUTgwfDLbcUHYUkSaoN22w0E++8A6uvDu+9F7M7JUlS6dhmQ7XStSsMHAiDBsEb\nbxQdjSRJ+j4maM3I9dfDjjvC+uvDyJFFRyNJkubHLc5maOhQuPJKeOihaGorSZIallucWmC//CV8\n/DHceWfRkUiSpJqYoDVDLVvCqafC4YfD5MlFRyNJkublFmcztvvu0K1bJGuSJKnh1HeLs6QJWkqp\nG3AF0AWYAVyUcz67huuqgDOB1sCHOeeBNVxjgtbAPvggWm/ccUdMGmjheqokSQ2i3BO0LkCXnPPI\nlFI74Blgx5zz2LmuaQ88Bvw45/xOSqljzvmjGt7LBK0Err4a9toLVlwRxo0rOhpJkpqGsi4SyDm/\nl3MeOev+JOAloOs8l+0B3JhzfmfWdd9JzlQ6u+8O33wTw9TffrvoaCRJEjRikUBKaXlgDeDJeV7q\nBXRIKT2QUnoqpbR3Y8Wk0KIFDBgAjz9edCSSJAmgVWN8yKztzRuAw2etpM0bw1rAIGBR4PGU0uM5\n51fmfZ8hQ4b8935VVRVVVVWlCrnZ2WADeOwx+OlP7Y0mSdKCqq6uprq6usHer+RVnCmlVsDtwF05\n57NqeP1ooE3O+c+zHv9r1rU3znOdZ9BK6MEH4yza119H0cDaaxcdkSRJlausz6DNcgnwYk3J2Sy3\nAhunlFqmlBYB1iPOqqkRrbMOLL007Lor/OY3YC4sSVJxSrrFmVLaENgTGJNSeg7IwB+B7kDOOQ/N\nOY9NKQ0HRhOtOIbmnF8sZVz6rkUWgREjYMaMaLkxbBjssEPRUUmS1DzZqFbfceONcMop8OSTnkeT\nJKkuKmGLUxXmJz+Br76KVTRJktT4XEFTjR54IIoGRo2Cjh2LjkaSpMpS1pMEGpIJWuP77W/h9dfh\nhhtg+nRo3broiCRJqgwmaCqZqVOjunPSpKjwfPRRz6RJklQbnkFTybRtC7fcAhddBFOmxH1JklR6\nrqCpVu6+O/qjjRkDrRpl/oQkSZXLFTQ1ii23hC5d4PLLi45EkqSmzxU01dqTT8LOO8Po0dChQ9HR\nSJJUviwSUKP6zW/grbeislOSJNXMBE2Nato0WG45eOIJ6NGj6GgkSSpPnkFTo2rTBgYOhAcfLDoS\nSZKaLhM0LbCqKqiuLjoKSZKaLhM0LbCqqhgFddllsN12cN99RUckSVLT4hk0LbCc4xxar17Qs2cM\nVv/Pf4qOSpKk8mGRgAoxeTIssghMnAirrQbvv++sTkmSZrNIQIVYZJH4ucwysNJKFg1IktSQTNBU\nbwcdBD//OQwfXnQkkiQ1DW5xqkHcdx/svTeMHw/t2hUdjSRJxfIMmsrG7rvDG2/AkkvCbbdBqvN/\nLSVJqmyeQVPZOPXUmNX56qtw771FRyNJUuVyBU0N7pJL4Prr4a67io5EkqRiuMWpsjN1Kiy/PNx/\nP6y6atHRSJLU+NziVNlp2xZ+/Wv4xz+KjkSSpMrkCppK4oMPYOWVo7pzrbWKjkaSpMblCprKUqdO\ncRZt663h9deLjkaSpMriCppK6uijYcoUOPvsoiORJKnxWCSgsjZxIvTpE+fRttgiRkNJktTUucWp\nsrbMMnDCCXDGGXDBBUVHI0lSZWhVdABq+g47DJZbDi66qOhIJEmqDK6gqVGsvTY8/TS8/TY8/HDR\n0UiSVN48g6ZGkTMsvTSsvjp89hk89VTREUmSVDr1PYPmFqcaRUqxinbvvdCqFXz+ObRvX3RUkiSV\nJxM0NZqNN4auXWHChNjm3G67oiOSJKk8ucWpRjNjRqyk/e1v8OmncPrpRUckSVJp2GZDFaNlS2jR\nArbcEm64ASZNKjoiSZLKkwmaGt0668Amm8ARR8C77xYdjSRJ5ccETYX4xz+imrNPn5gw8OmnRUck\nSVL5MEFTIZZcMrY5330XlloqJg1IkqRgkYAK99pr0YJj/PhI3CRJqnQWCaji9egBP/0pnHZa0ZFI\nklQeXEFTWXjzTVhjDRg7Fjp1KjoaSZLqxxU0NQnLLQfbbhvn0iRJau5M0FQ2Nt4YRowoOgpJkopn\ngqayse668OSTRUchSVLxTNBUNlZbDd56C/70J9h0U3jppaIjkiSpGCZoKhutWsFaa8Gpp8akgcGD\nYebMoqOSJKnxmaCprGy/PQwZAn/+M7RrB3feWXREkiQ1PttsqGxddRWcey48/HAMWpckqVLUt82G\nCZrK1owZMGgQrLwytG0Lp58OrVsXHZUkST/MPmhqslq2hP/8B95/H2691RYckqTmwwRNZa1bt0jO\ndt0V7ruv6GgkSWocJmiqCIMGRYJ27bXw3ntFRyNJUml5Bk0VYdIk6Ngx7v/kJ3D11cXGI0nS9/EM\nmpqFdu3grLNg1Ch45BF47LGiI5IkqXRcQVPF+fe/I1n7wx/giy9g332LjkiSpG8r6zYbKaVuwBVA\nF2AGcFHO+ez5XLsO8Diwa875phpeN0ETENMFNtgAXnwROnWCl1+GVOf/CUiS1PDKfYtzOnBkznlV\nYABwSEpplXkvSim1AE4G7i5xPGoCWrSA66+P7c5p02Ds2KIjkiSpYZU0Qcs5v5dzHjnr/iTgJaBr\nDZceCtwAfFDKeNR0LLss9OgRo6GGDSs6GkmSGlajFQmklJYH1gCenOf5ZYDBwAWAG1VaIIMHx5k0\nh6pLkpqSVo3xISmldsQK2eGzVtLm9g/g6JxzTnGQaL5J2pAhQ/57v6qqiqqqqgaPVZVliy1g0UUj\nSfv5z4uORpLUXFVXV1NdXd1g71fyKs6UUivgduCunPNZNbz+6uy7QEfgK+CAnPNt81xnkYBq9Nhj\nsNNOcPvtsPbaRUcjSVKZV3ECpJSuAD7KOR9Zi2svBYZZxakFdcstsP/+cP/9sPrqRUcjSWru6pug\nlXSLM6W0IbAnMCal9ByQgT8C3YGccx46z6+YgalOBg+GyZNhq62ge/fY8lxhhaKjkiSpbmxUqybl\nwQfhtNNg223hoIOKjkaS1FyVex80qVFtummspj3ySNGRSJJUdyZoanI22ggefrjoKCRJqjsTNDU5\nvXrBlCnw5ptFRyJJUt38YIKWUuqVUrovpfT8rMd9U0rHlT40qW5Sgq23jmHq33xTdDSSJC242qyg\nXQT8AfgGIOc8GtitlEFJ9XX++fDxx3DUUUVHIknSgqtNgrZIznnEPM9NL0UwUkNZZJFotXHNNXDH\nHTDd/8ZKkipIbRK0j1JKPZnVoyyl9FPg3ZJGJTWAjh3hX/+C3/0uJg1IklQpfrAPWkppBWAosAHw\nKfAasFfO+fWSR/ftOOyDpjqZNg2WXx7uuQdWW63oaCRJzUGjjXpKKS0KtMg5f1nXD6sPEzTVx1/+\nAqNGwX/+AwstVHQ0kqSmruQJWkrpTzU9n3P+c10/tC5M0FQfn30Ge+4JH30ETzwRlZ6SJJVKY0wS\n+Gqu2wxga2D5un6gVIQlloDbb4f334cXXig6GkmSvt8Cz+JMKbUB/i/nvGlpQprv57qCpno77DDo\n0gX++MeiI5EkNWVFzOJcBOha1w+UirTDDnDbbUVHIUnS92v1QxeklMYwq8UG0BJYCmjU82dSQ9lk\nE3jlFXj1VVhhhaKjkSSpZrUpEug+18PpwPs550Zv++kWpxrKkUdCmzZw0klFRyJJaqpKtsWZUuqQ\nUuoAfDnXbQqw+KznpYp04IFwySVw3nmwyirRekOSpHIy3xW0lNJrxNZmTdlfzjk36gaRK2hqSOec\nA888Az/6ETz/PNxyC0yZEtMHJEmqr0ZrVFs0EzSVwuTJsMwy0LcvdOgQiZokSfVV3wTtB4sEZn3I\nj4CVgLazn8s5P1TXD5XKxSKLwLbbwksvxaSBadPifJokSUWqTZHAr4DDgW7ASGB94PGc86DSh/et\nOFxBU0l88gm0bAlbbw0nnACbbQYt6tKARpKkWRqjD9rhwDrAGznngcCawGd1/UCp3HToAO3bwzbb\nwH77Qc+ecR5NkqSi1CZBm5pzngoxRSDnPBZYubRhSY1v333hqKPiPNrZZxcdjSSpOavNFufNwH7A\nEcAg4FOgdc55m9KH96043OJUoxg/HgYMgIkTPY8mSaqbRq3iTCltCrQH7s45f13XD60LEzQ1pg02\ngOOPhy23LDoSSVIlKvkZtJTSWSmlDQByzg/mnG9r7ORMamyDB9tyQ5JUnNqcQXsWOC6l9EpK6dSU\n0tqlDkoq2uwE7e67YXqjDzaTJDV3td7inDXeaWdgN2C5nPNKpQyshs93i1ON6i9/iSRt4YXh+uuh\nS5eiI5IkVYrGaLMx24rAKsDywNi6fqBUKY47DkaMgE03hc03h48/LjoiSVJzUZsqzlOAnYAJwLXA\nzTnnRu+D5gqaipIz/OpXsPTSsaomSdIPaYwVtNeAATnnrXLOlxaRnElFSikStJtvjseTJsEjjxQb\nkySpaXNYulQLM2dCt25QXR23v/8dXnml6KgkSeWqMc+gSc1WixZR2XnttXDHHTBhArz/ftFRSZKa\nKlfQpFp64QUYOBCmToXeveEPf4ikTZKkedV3Ba1VLT6gJ/B2znlaSqkK6Atc4Vk0NTd9+sRA9Vde\nga22goceivNpXbrAeusVHZ0kqSmpTRXnSGBtor3GncCtQB9ncao5+vxz+PBDePPNaL2x1lqRsI0Y\nAb16FR2dJKlcNMYZtJk55+nAT4Bzcs5HAUvX9QOlSta+Pay4Imy0EVx5JTz5JGyxBTz1VNGRSZKa\nktokaN+klHYH9gFun/Vc69KFJJW/hRaCPfeEli2hf3945pmiI5IkNSW1SdD2AwYAf805v5ZS6gH8\nu7RhSZXDBE2S1NAWqIozpfQjYNmc8+jShTTfz/YMmsrSxx9Djx7w2Wdw443wox/F+TRJUvPVGFWc\n1cAOs659BvggpfRozvnIun6o1JQsuWTcxo2DU0+Ftm1N0CRJ9VObLc72OecviHmcV+Sc1wP81480\nl+23hzPPhPHjYexYePXVoiOSJFWy2iRorVJKSwO7MqdIQNJcDjwQLrooVs522w2uuKLoiCRJlaw2\nCdqfgeHAhJzzUymlFYCXSxuWVFn69Ink7Cc/gX32iQRt5syio5IkVSpHPUkN5JtvoHVryBlWXx3O\nPx823rjoqCRJRSh5o9qUUreU0s0ppQ9SSu+nlG5MKXWr6wdKTVXrWd0BU4pVtAsuKDYeSVLlqs0W\n56XAbcAyQFdg2KznJM3HgQfCY4/BHXcUHYkkqRLVahZnznmNH3qu1NziVKV56CHYddf46ZxOSWpe\nGmMW50cppb1SSi1n3fYCPq7rB0rNxSabwF//GrM6H300ntt3X+jaFYYNKzQ0SVKZq80K2nLAucS4\npww8BhyWc36z9OF9Kw5X0FSRbrkFDjgAjjkGzj47krQPPoDzzis6MklSqdR3Ba1OVZwppSNyzv+o\n64fWhQmaKtmwYbDDDpGUrbkm/PrX8NxzRUclSSqVohK0N3POy9X1Q+vCBE2V7u67YeDAuN+hQ6yi\nLbposTFJkkqjMc6g1fi5df1Aqbnaaito0yZuffvChRfCiBFFRyVJKkc/OCx9PlzKkupho43g+OOh\nXz945JGio5EklZv5bnGmlL6k5kQsAQvnnOua3NWJW5xqSqZOhWnTYLnlYrD6kksWHZEkqSGVbIsz\n57xYznnxGm6L1TY5mzWF4P6U0osppTEppcNquGaPlNKolNLIlNIjKaXV6/plpErRti20bx9n0u68\nE956K0ZESZIEdd/irK3pwJE555EppXbAMyml/8s5j53rmleBTXLOn6eUtgIuAtYvcVxSWdhuO/jF\nL6BdO+jcGZ54ApZYouioJElFa9Rh6SmlW4Bzcs73zef1JYAxOedla3jNLU41OVOnwvPPQ//+0Xqj\nZUv45z+LjkqSVF+FtNmo0weltDxQDayWc540n2t+B/TKOR9Qw2smaGrSPv0UeveOnmnrrFN0NJKk\n+qhvgtYoB/1nbW/eABz+PcnZQGA/YKP5vc+QIUP+e7+qqoqqqqoGjVMq0o9+BKecEitpQ4fGytrG\nG0OPHkVHJkn6IdXV1VRXVzfY+5V8BS2l1Aq4Hbgr53zWfK7pC9wIbJVznjCfa1xBU5OXc4yFGjEC\nJk+GPfaAE04oOipJ0oIq+y3OlNIVwEc55yPn8/pywH3A3jnnJ77nfUzQ1KxcdVXM8bzuuqIjkSQt\nqLJO0FJKGwIPAWOInmoZ+CPQHcg556EppYuAnYA3iB5r3+Sc163hvUzQ1Kw89xz8/OcwZkzRkUiS\nFlRZJ2gNyQRNzc3kydHA9p57oLoajjuu6IgkSbVlgiY1YT16QMeO8OyzcS6tf/+iI5Ik1UZRw9Il\nNYLevWOr829/g4MPhunTi45IktQYTNCkMta7N2y2GRx1FCy+OJx0UtERSZIag1ucUhkbPx6mTIF+\n/eDtt2H11WHsWOjUCVKdF84lSaXmGTSpGTnoIPjiC3jwQbjtNs+kSVK5MkGTmpHx42HVVWGrraBV\nq+iTJkkqPyZoUjPz0Uew6KLQsydcfTVsumnREUmS5mUVp9TMdOwICy8Ml18Ou+4KL7xQdESSpIZm\ngiZVqC22gNNPh623htdfLzoaSVJDMkGTKthee0ULjrXXhn//u+hoJEkNxTNoUhPw/PMwaBDceWck\na5KkYnkGTRKrrQZnngmHHFJ0JJKkhmCCJjURu+0G77wDY8YUHYkkqb5M0KQmomVL2GcfuPjioiOR\nJNWXCZrUhOy/fxQLvPFGPL7tNpg2rdiYJEkLzgRNakKWXx5+8xs4+OAYCbXLLvDkk0VHJUlaUCZo\nUhPz+9+M4mZJAAAgAElEQVRH89o//Qm+/jqGq0uSKosJmtTEtG4dq2hnnRXVnS+9BHaokaTKYh80\nqQmaNCkGqh9wAFx1VWx99uoFRx5ZdGSS1Dw4LF3SfE2YAJtsApMnR5XnCy/AJ5/Aww9H8iZJKg0T\nNEnzNWMGLLoorLkmbLhhTBz47DP4/PPY+pQklYaTBCTNV8uWsbU5eDCcdBL86Efx3Ouvw8yZRUcn\nSZofV9CkJm7YMFhvPejUKYoFZs6Ebt3gqafgq69g5ZWLjlCSmh5X0CR9r+23j+QMIKVYQevZEx54\nAFZZxdFQklSOTNCkZqhnT7jiimjJcdppRUcjSZqXCZrUDPXsCffdF01thw2DceOKjkiSNLdWRQcg\nqfGtsEKcR9t+e+jcGfbbL1pvtGxZdGSSJHAFTWqWevaEtm2j/cYhh8TZtKuuigICqzslqXhWcUrN\n0LRpcPvtsPPO8fjee+HQQ6F9e9hxR/jDH4qNT5IqnY1qJdVbzrDxxrGq9s478OKLsaomSaobEzRJ\nDeKbb6BVK+jRA267Dfr2LToiSapc9kGT1CBat45Vs912g4su+vZrX35ZTEyS1Fy5gibpWz78EFZf\nHe64A/r3h4kTY1zUxImw+OJFRydJlcEVNEkNaqml4MQTYciQeHzJJTESavToQsOSpGbFBE3Sdwwe\nHH3Rvv4a/vUvWGcdGDmy6KgkqfkwQZP0HUstBV27wqmnQseO0ch21Ci480445RR4662iI5Skps0E\nTVKNNtkE/vxnOOAA6NcPqqthr73g+edjAsGUKUVHKElNlwmapBptuikstBDsvnsUDUyYALvuGkPW\ne/eG//mfoiOUpKbLBE1SjQYPhuHDYbHF4rbPPnD00dGK46KL4PHH4cori45Skpom22xIqpMbb4RL\nL42RUZKkb7PNhqRC9OsHY8bAZ5/BscfCs88WHZEkNR0maJLqZIUV4OOP4eqr4YYbYLPN4N13o+Kz\nRw945JGiI5SkyuUWp6Q6W2+9GAN10EHwwgvwyisxcWDQIOjQIRreSlJzVN8tzlYNGYyk5qVv32hk\nO2gQVFXFtudVV8VIqDPOKDo6SapcJmiS6mz11aFTJ+jTJ6o7hw2DrbeOc2lPPQXTp0Mr/ykjSQvM\nf3RKqrMtt4QZMyI5A9huu/i55JIxiWD0aFhzzXjuiy+gffti4pSkSmOCJqnOVl45bjUZNAj694f/\n/d/YCj3uOHjppTnJnCRp/iwSkFQSOcPYsVHduf76cPPN8NxzsMYaRUcmSaVnHzRJZSmlGAnVpUs0\ns/3Vr+D664uOSpIqg1uckkpq773hnnvgkENgiy2ge/cYwC5Jmj+3OCWV1MyZMGUKLLooPPlkbHm+\n9RbssgucckqcU5OkpsYtTkllrUWLSM4gGtv26RPVnY8+Co89VmxsklSuTNAkNao+feCWW2Dq1Jjf\n+cwzMH580VFJUnlxi1NSozrjDDjttGhg26FDTB1YZRUYOrToyCSp4bjFKamirLZaDFXfYw8YNy7O\npVVXFx2VJJWXkiZoKaVuKaX7U0ovppTGpJQOm891Z6eUXk4pjUwp2SVJasL69Imf664LK60UidrH\nH8M778RUgtdeKzY+SSoHpW6zMR04Muc8MqXUDngmpfR/Oeexsy9IKW0N9Mw5r5RSWg+4AFi/xHFJ\nKsgyy8T8zjXWgIMOisKBzz+HBx+EyZPhpJNgwoSio5SkYjXqGbSU0i3AOTnn++Z67gLggZzztbMe\nvwRU5Zzfn+d3PYMmNRGff/7tuZwXXxxn0L78MqYPfPqpczslVbaKOYOWUloeWAN4cp6XugJvzfX4\nnVnPSWqi5k2+9tsPVlwR2rSBddaJNhyS1Jw1yiSBWdubNwCH55wnzftyDb9S41LZkCFD/nu/qqqK\nqqqqBopQUpFatIArroBJk+D3v4dRo2Djjb99zYQJsPDCsUUqSeWmurqa6gaseCr5FmdKqRVwO3BX\nzvmsGl6fd4tzLLCpW5xS83TeeTFU/aKL5jx3zTWw776w//5wzjmFhSZJtVYJW5yXAC/WlJzNchvw\nc4CU0vrAZ/MmZ5KajzXWgJEjv/3c6afDb34TiRvAJ5/AH/7Q+LFJUmMp6QpaSmlD4CFgDLFtmYE/\nAt2BnHMeOuu6c4GtgK+A/XLOz9bwXq6gSc3A5MnRuPakk2DPPaOgoFs3ePll6NULPvsMHngAdtwx\nigpSnf//qSSVTn1X0JwkIKnsvPACbL45tG4NBx4YCdm990KPHjB8ODz0UGx3vvsudOkSvdROPBF6\n9iw6ckkKlbDFKUkLpE8fmDgR/vQnOO44GDgwnl9zzZjf+eqr8fiVV6K57c03w8MPFxevJDU0EzRJ\nZSkl+OUv4be/hZ/+NJ5bc804h/baa9C2bSRoEybMGbwuSU1Fo7TZkKS6SCkGq8+2/vpwwgnwzTew\nySaRoC22WAxdN0GT1JR4Bk1SxZg8OcZEtWoVW59PPw29e8P778OVV0ZBQQv3BSSVAc+gSWo2FlkE\n+veHadNgo41iBW3MmGhqu9RSUek5blwUEUhSJTNBk1RRBg6Mas5evSIZe+ABWH112GADuPvumESw\n9dZw8snw9ddw330//J6SVG48gyapouy8M8ycGefOqqvh0Udjm/Pgg2HXXWMb9Nln47za9Onw5z9H\n77RFFik6ckmqPc+gSWoyBgyAvn3hwgujAvSSS2DppeHf/4ZBg4qOTlJzYqNaSZrl7behXTtYYolo\nv3HVVfDVV9GSY8iQoqOT1JyYoEnS97jrrjiPdsYZsNZajoaS1DhM0CTpe3zxRbTmmDkzzqxtsEE8\nP3w4jBoVRQWS1NBM0CTpB0yaFMPXIQasb7UVXH453HhjjIgaMKDY+CQ1PfVN0KzilNTktWsH220H\nu+wSA9bHj4ennoJTT41h7M89F8/PPr8mSUVzBU1SszBjBnTpAnvvHVWeK6wAo0fDpptGC47HH4++\nae+8Ey08JKk+nCQgSbXQsmVsaQ4ZAoMHxzZnSnDmmTGZ4KWXYO21YzVNkormCpqkZmfSpEjYFl74\n288ffjgsuyz87nfFxCWp6XAFTZIWULt2303OANZc89sraO+/DzfdBK++2nixSRK4giZJ/zVqFOy2\nW2x3zpgBG24IbdrAa6/B88/D4osXHaGkSuEKmiQ1kFVXhTfegFdegaOPjuTsgQfivNqxx373+r/9\nDUaMaPw4JTV9JmiSNEvr1rD//jFofcKEmOHZokWcTRs+HKZMiUa306fH9ddeC3ffXWzMkpomtzgl\n6Qd8/XVsbz7wQCRozz0Hq68Oiy4aq2u33FJ0hJLKjY1qJanEFloIuneHm2+Ox08+CYstFm06nn22\n2NgkNU1ucUpSLfTuDdddBz16RIL24ovR5PaLL+DDD+dcN3MmPPZYcXFKahpM0CSpFnr3jgKCX/4S\nnngiKj1XXfW7rTnuuw822yyqQCWprkzQJKkWVlklfu6xB7z1Ftx6ayRtAwZ8u1Dgsstg6lR4881C\nwpTURJigSVIt9O4N7dvD8stHdeeYMbDGGvDrX0dS9skn8PnncMcd0L9/rLDNnFl01JIqlVWcklQL\nM2bE2bMNNojHU6dC27Zx/xe/iMRt6aVjNa1bt7j9619wyikx+1NS81LfKk4TNEmqp3HjYKONYLnl\nYhj7O+/AeedF8cD06bDkkjHf81e/gsmTYzJBnz5FRy2plEzQJKkM7LILPPQQvP12VHFWVcExx8CO\nO8aZtUMOiW3Pa66BK6+MQgNJTZcJmiSVgQkT4lza4MHwwQfQuXMkagMGxOuHHBKjo8aMifFQn30W\nfdQkNU0maJJUZnKGM8+MEVEtW8ZzEyfCaqvFlmfLlvDCC7DMMsXGKal0HJYuSWUmJTjyyDnJGUQy\ntvvu0dy2b1949FHo1w9OOCFGSUnS3FxBk6RGMm0afPUVHHssPP00tGsHiywSCd0FF0TlJ0S16PDh\n8L//O2cb9LLLogfbQgsVFr6kBeAKmiRViDZtoEOH6Kn29NNR1XnLLbDiijF8ffjwuO6f/4STT45t\nUogVtv33h1GjiotdUuMyQZOkRta7N7RqBdtuC61bwz/+Ef3SLr44VtmGDYPbb4fTTovzbOPGxdm1\nF14oOnJJjcUETZIa2YABcOGFsMQSc57beedYQbvmmuiRNmhQNMJ98cWo/AQTNKk58QyaJJWJ7beP\n4oErroDttoMDDohk7b334J57oFMnuPPOoqOUVBu22ZCkJuLjj2Prs337eHz99XD55XG/qgrOOQfO\nPz+qQGcXFEgqTxYJSFITseSSc5IzgC22gJEj4f77YYcdYnTUTjvFjM955Qx33RU/JVU+V9AkqYy9\n/HK027jqKthkE+jaNWZ9PvIIjB0blZ7t20dxwdlnRzI3cGD87hdfRMK22GKR3HXuXOx3kZoTtzgl\nqZn45pu4deoUo6UGDoxZny1axErbuuvC88/H1mjO8XrPnrDBBpHIPf980d9Aaj7qm6C1ashgJEml\n07p13NZdF9ZZBzbbDE46ac7rX34J3btHm44XXoiZoKNHwyuvxOMJE+LnDjsU9x0k1Y4raJJUYYYN\ng3ffjUa3LeY5SVxdHdWfyy4L554LBx4Izz4bPdfeegsefzx+WmQglZZbnJKk+bryykjKBg2CXXaJ\nth1HHQX77FN0ZFLTZoImSfpeOUcRwZ13RiuPhx6KxE1S6dhmQ5L0vVKKqQQ77QSbbw733gszZ8YN\n4IknolJ05Mg5v5MzHHIIfPppMTFLzZ0JmiQ1Iz16RKPbDTeEpZaKKtAdd4TXX4fDD59z3QMPwHnn\nwVNPFRaq1KxZxSlJzcwdd8QWZ79+MaD9L3+Bn/40KkA//hj+53/gzTejncfo0fDjHxcdsdT8eAZN\nkgTAiivCbrvBrbfCMstE5efTT8dsUIAZM+K20ELFxilVAs+gSZIaxDrrxDSCww6D4cOjwe3o0XNe\nP//8OMM2++yapNIxQZMkAbD22tHsdptt4vGqq8K4cTG9AOI82ogRcOml83+Pt96C11779nOzt1M/\n+aQ0cUtNkQmaJAmAjTeGAQNi3ifAIovEubTHHovHo0bBCSfA0KHzf4/DD48JByNGRKHBe+/FmbZJ\nkyLZk1Q7JmiSJCBGSD366LefO/HEKCB4+OFIsPbbL2Z6zl5Vm9t770VStummkaT94hdxhm299eK9\nJ0xonO8hNQUWCUiSvteFF8I//hG90caOja3Pq66CNdaYc03OcMwxUQU6dChMnRqrbzvsAJ07x0iq\n1q3h+OOL+x5SY7JIQJJUUnvuCe+8E/3TIM6qPf00fPhh3P/0Uzj66JhUcNxxkYwtsghssgn85z9x\nzQorfHcFbcYM+Oyzxv8+UiUoaYKWUro4pfR+Smn0fF5fPKV0W0ppZEppTEpp31LGI0lacO3axTmy\nqqp43L9/JGhHHw3PPRcD2i++GO66C5Zffs7vbbxxjJhaZx3o2RNefTXOos3eDDniiKgUnT69kb+Q\nVAFKusWZUtoImARckXPuW8PrfwAWzzn/IaXUERgHdM45f+d/rm5xSlKxco6xUU88EYnVyivDT34S\n59M++gheeunb148aBVtvHatvb78d59C6dYNf/Sp6ru23Xzz+5S/jJjUl9d3iLOkkgZzzIyml7t93\nCbDYrPuLAR/XlJxJkoqXZv2rZr31YtJA167w5JNw0klw6KHfvb5fvygoSCmu/eST2A695ppodvvX\nv8Iqq8BWW8X7HXoodOz4/THMnBkreHfdBV26NPx3lMpF0WfQzgVWTSlNBEYBh//A9ZKkgqUUK18p\nRbLUrl00sK1Jhw7xs0WLOId28smxLfrss7DLLrH9+eyz0T9tlVV+uFfa+PEx1P2mm779/KRJ8MYb\n9f9uUrkoehbnlsBzOedBKaWewD0ppb4550k1XTxkyJD/3q+qqqJq9oEISVIhWreG66+HgQN/+Nrr\nrosk7NlnY85n27bxfPfucMklsNNOMWZq772h1Xz+7fTkk7HKdsMNcPDBsd3asSPcfz8MGxY3qQjV\n1dVUV1c32PuVvM3GrC3OYfM5g3Y7cFLO+dFZj+8Djs45P13DtZ5Bk6QmYMqUSOzmTcKuvhrOOw8m\nToyRU9tu+93fPfhgWHZZOOUUePnlKDRYaSWYPBluvjmek8pBJbTZSLNuNXkD2BwgpdQZ6AW82ggx\nSZIKsvDCNa+QbbddjJNaaKEYDwWxYnbiifD553Meb7pp9GB7/vkoPhg3Dl55JapEp0379nsed5xb\nn6pMJd3iTCldBVQBS6aU3gSOBxYCcs55KPAX4LK52nD8PufstDZJaoYWWywmGSyzTGyFfvVVtPKY\nNg1uuw3uvjsa5a65Jiy3XCReb78NX3wRxQMtWkSi1qdPvN+MGbESt9pqsY0qVZJSV3Hu8QOvv0uc\nQ5Mkif794+cGG0SD3Ndei23L/v1h++1hr71iBa57d3j99dgOfe+9KFjYeONI4GYnaGPHxvD32due\n1dXw7ruw++5FfDNpwRRdxSlJ0ndcfnmskp18cmx5/vGPMHp0DGuHeO2552JiweKLR9K27rrf7sU2\nYgS0aTMnQbvmmphs8M470Xh3fseav/jCbVEVr+gqTkmSvqNTp9ienG233WCjjeb0PuveHR57LNp9\ndOgQhQerrAJ33BFbmy1bxnm17befk6CNGBGjpR54AP75z5gT+uMfx/m2xRef0+ftuOPid+66q3G/\nszQ3V9AkSWUvpajenG255WJ6QdeuMdFgxRVj9udzz0XbjZ//HG6/PbZEX3klErixY2OL89FHY8v0\nhBNiFa1vXzjwwBg59dVX8O9/R/uOmTOL+76SK2iSpIqz3HLxs1s32HHHSKxWWCGSsXfeieRsvfWi\nVcfUqXH+rHdv+Oab6KF22WWRvD31VLz+yivwv/8byd1GG0WF6Lhx8Ttzu/HGSO7mnjkqlULJ+6A1\nFPugSZLmttRSMR7qT3/6/uvWWitW2rp1iy3Oa66JwoIDDojKT4ALL4zWHa1awf/9X7T22Gwz+MUv\nYsrB7NW7ddeFn/0Mfvvb0n43Vb5K6IMmSVKD6949kq4fsuGGMQP0gANg1VXjHFvnzjH94JZbomK0\nUye49944t7bKKjBgADz+OLz/fnzOv/4V26Fjx8aqm1RqbnFKkirSbrvFNuYPOeecOfffey8SNoDZ\n0wIHDIifq64657oBA+D88+NM26qrwu9/H/3UpkwxQVPjcItTktQszZwZPdEuuyzadMztm2/gRz+C\nQw6JqtDXX49r3nwzhrW/+iosuWS8x8SJ317Jy3lORaiaL7c4JUmqgxYt4Nprv5ucQcwKXXttuPTS\nOJs2cGAMe19ttTjT9vSsidFXXRXVo7PlHCtzl17aKF9BTZgJmiRJNRgwAD78MEZLDRoEX38dVZ2b\nbw5Dh0YyduWVMe1g7FjYZZdI+F57LbZEd901+rJJdeEWpyRJNbjttqjY/PLLaHy7zDLRI23DDWN1\nbYstYnu0qgomTYqzaV98EWfe1lwzGumefXY0vW3TJrZD77wzhsKr6avvFqcJmiRJNfjyy9iqPOyw\neDxmTKygtWoVfdNOPTUqPDt1gv33j/YdH34I++4L7drF72y7bTTHXXPNaJ47cCB88gkssUTdYnr7\n7TgDZ5JX/kzQJEkq0BtvwNZbR8Vnmzbffu3VV2Ml7YgjouL0zjvh7rthyy3n/34zZ8IZZ0SvtXmL\nDYYOhdNOg/HjG/57qGFZJCBJUoG6d4cXXvhucgYx3WCvvWDvvSM5+9nPImGb17RpsT0KsVV61FHw\n4otRTTq3V1+NLdNXX23476HyYoImSVI9/VBbjUMPhV//OhK1hx6C00+PhOydd2LEVPfu0dcNYkxV\nq1YxrH311WMu6GyvvQbt28Pw4aX7LioPbnFKktRIPvkk+qe1aAFXXx23RReNfmtbbhl91gYNgk03\nhcsvjwkIp502Z7TUuutGdelrr0URww/JOVbi+vQp7ffSd3kGTZKkCnLzzZE0vfFG9FYbPz4KDXbc\nMVbSrroq2nZ07gw//nE0zB06NHqzde0Kjz4a59leew1Gj4aNN44VtfXXj4a6J54IvXrBySfHiKr9\n948B8TvvXPQ3b17qm6A56kmSpEb0k5/E8PVNNolEqlOneH7nnWNe6E03QceOMbS9Q4fY+tx77xgO\nP2VK/M6Pfwy/+lVcu9lm8MADcPjhUF0NO+0EF1wQCd0FF0SvtgMPjLYgiy8eK29LLw3rrFPofwz6\nASZokiQ1sjXWiARq883nPLfnntFjrWfPeLzZZjB9erTWmDgxCgl69Yrzbj//OWy/PVx/Pdx6azTE\n3WmneP3YY6FfPzjppDjHtvbakag99VS853nnxUSEnj1jFa5//2L+M9D3c4tTkqQCHHxwVHhusMH3\nXzdgQJw9e/BBWG65WAGbPj3adczdD+2MMyLxGzTou+9x5JGxUnf00bF12q9fJIcnnwwvvQRdujTs\nd5Nn0CRJatJGjIAePaIR7scfw5AhC/4eV18d59DOPhtWWikKE9ZfP6pIV1klzr3VZMaMuC20UL2+\nQrNkgiZJkr7XK6/Eyto//xm3Z56Br76K5rrrrTenUGG2Qw+N7dDx46PtR3V1VJ6q9mxUK0mSvlfP\nnjEv9JprYK21Youzc2dYeeWoHv3Pf759/fDh8dzNN0dy989/FhN3c2aCJklSE5cS/O1vsRq2/vqR\noG24Yby2775w/PFRYPDFF/D551GYMHx4nE+7+eboxVabTawPPog2H6o/tzglSWomvv46qkfffjvu\n9+wZidfTT8MJJ8RqWq9e8Mc/xvWdO8ONN0bV59FHR9+2226L7c5jj41t04ED4z1atoxE729/i0Hz\nbdsW+12L5hk0SZJUb7ffDn/5C+y6a7Tf2H57WGyxqCI98cQoTkgpzq/17Rt92dq0ibNrG28Mf/97\nNNqd/V7Nvc+ajWolSVK9bbUVHHFEbGf+9a/RDHe2ffaB996Lis577oGFF45K0COOiP5sf/97JHPr\nrBMJ2zPP1JygPfxw9Gw7+eTG+16VyhU0SZIERBuPv/0t+qZ17frd12++OZre7rkn3HlnFB0A7L57\nbH0+/3w8P3IkXHTRd39/332jpcebb9a+99qHH8ZqXaVxi1OSJDWKzz6LZrkbbhgrbocfHs9PmBDV\nnltuCU88EWOr2raNKQerrRbXzJgRSVn//rEleuyxP/x51dWwzTZRvNCqwvb8bLMhSZIaxRJLwLnn\nwv33z6kChSg22HLLuN+vH6ywQhQQ/Pa3UUBw331wzDHQrVuMoLrwwkjYZjvgAHj22W9/1tSpUaww\ndWoMgW9uTNAkSVKt/fzn8O67MeOzJgsvHGfNzjsP3nortjr33ju2NY84AtZcM7ZP77gjrs85hr7f\ndNOc93j00UgGF1kkRlKNHfvtzxg6FJZZJlbi7r13znvMlnMMm58woWG/e2MyQZMkSQukQ4cfvqZ1\n6xgxdfjhMZXg2muj2ADg17+GM8+Eb76JZO/jj6Pv2iefRB+2Bx+E//mfSL769PlugnbVVVHM8Ktf\nxerbhAmxrfrCC/H6PvvE8PizzmrY792YTNAkSVJJ9OsX25tnnvnt53fdNc6oVVVFxefGG8dYqQED\nop3HmDHRygNiVujYsXGbOTPOoz3zDAweHKt5kybNmYRw3XUwbFicgxs2DB55JJrtHn00vPpqY37z\n+rNIQJIkNbqcYYMNosHtuuvGFui778KUKdFE98orYzv0wQfhoIPgjTeiinTy5KgkHT483uenP40k\ncPDgaAEyfXqssG24ISy5JOywQ2y1jhsHt9wSn9kYLBKQJEkVJyX4xS/ivFnfvrEK9sAD8PLLsWXZ\nu3dcN3sFrXXreP3226OCdLZNN43q0qOOigrRyy+PAoU2bWLu6LXXxlbrlVdGEje7OOGgg75bmFBO\nTNAkSVIhZm919u0bCdVCC8VqWo8ec0ZFdeoUCdn550dhwc03w89+Nuc9Bg2KgoHevaOtx+xqUoCN\nNooig27d4vkll4TRo2MU1SWXRLJXG3/6U1w/P2PGxKpfQzJBkyRJhWjfHp56KrYyZ9t00znnzyBW\n2u66K4oAXnklhr0vs8yc1/v0ie3LVMNm4jHHwGWXffu9q6ujwnPhhWP7dLacY6Vtjz2itQdEJeon\nn8R1t95a83f4+usogpi95dpQKqztmyRJakpmN7Kd7Ygj4uD/vNq0ifNke+/93dfatav5vRdfPG6z\nVVXF9IMlloDf/z5GTn39NXz6aVSEvv56rLYdemgkZ0cdFatuzz8fBQqPPhoFCocdNuc9hw2LaQcv\nvBDzSxuKRQKSJKki5FzzSlltvfsuLL98JGjPPhsJ31//Grf+/WOm6NdfxzUXXhgFCLvtFu0+lloq\nErnPP4+K0C5dIp4f/zjOtXXtGufcZrNIQJIkNQv1Sc4All46igbGjYuE6ogjIgFbeGE444w4A9eu\nXayEHX10bJ/edFOs8g0aFL+/335z2oYcfngkbMcfP6cHW0NxBU2SJDVbkydDixZzihIgige23z6m\nIBx4IBx8cMwOnTo1Kkb32AMeeyy2QydOjMSxc+coPpg6NVbU2rev3wqaZ9AkSVKztcgi331u881j\nC3ObbWL1bLXV4jFEn7bXXosGuCuvPOeM21JLxRm2U06J4of6cgVNkiRpHjNmRBPde+6B1Vefk6AB\ndO8eRQUvvhiVnwDbbRerZxMmwKhR9V9BM0GTJElaAFtsESOnttoKTjghnnvjjdgaHTgQVl3VIgFJ\nkqRG1asXjBgRP2fr3h0OOSSSs4ZggiZJkrQAZidmcydoDc0ETZIkaQHMTsxWWql0n2GCJkmStABW\nXRWWXTYa3paKRQKSJEkL6KuvYNFF5/96fYsETNAkSZIamFWckiRJTYwJmiRJUpkxQZMkSSozJmiS\nJEllxgRNkiSpzJQ0QUspXZxSej+lNPp7rqlKKT2XUno+pfRAKeNRcaqrq4sOQXXk366y+ferbP79\nmp72J78AAAiOSURBVK9Sr6BdCmw5vxdTSu2BfwLb5ZxXA3YpcTwqiP+QqVz+7Sqbf7/K5t+v+Spp\ngpZzfgT49Hsu2QO4Mef8zqzrPyplPJIkSZWg6DNovYAOKaUHUkpPpZT2LjgeSZKkwpV8kkBKqTsw\nLOfct4bXzgH6A4OARYHHgW1yzq/UcK1jBCRJUsWozySBVg0ZSB28DXyYc54KTE0pPQT0A76ToNXn\nS0qSJFWSxtjiTLNuNbkV2Dil/2/v/mO9qus4jj9fyPyBhZqJbaJg5fJHNKgJBlao6bSauJWpaaHT\nVosVrbKEWra1JlktKV2NVZOotPyBmn8EOkyWoTARJQWzGiEV2EoWaiLCqz/O52vnXr6XH3Xv/Z4v\n9/XY7u45n+85n/P+3vfuue97zuf7OdpP0ghgErBmEGKKiIiIaKwBvYIm6WfAVOBwSeuBq4H9Adue\nZ3utpEXAY8B2YJ7tJwYypoiIiIimG/AxaBERERGxdzr9Kc49IulsSWsl/V7SFzodT/TUbkJiSYdJ\nWizpSUmLypx3rde+I+kpSaskje9M1NEiabSkJZKekLRa0qdKe3LYcJIOkPRQmex7taSrS/tYSQ+W\n3N0kaXhp31/SzSV3yyQd09l3EACShklaKemusp78dQlJ6yQ9Wn4Hl5e2fjl3Nr5AkzQMuJ5qwtuT\ngIskHd/ZqKKXdhMSXwXca/tNwBJgFoCkc4A32D4O+Bjw/cEMNNp6GfiM7ROBtwMzyu9YcthwtrcC\np9meAIwHzpE0Cfg68K2Su83A5WWXy4F/ltxdB1zbgbBjZzOB+vCe5K977ACm2p5ge2Jp65dzZ+ML\nNGAi8JTtP9veBtwMTOtwTFHTx4TE04D5ZXk+/83ZNODHZb+HgEMkHTkYcUZ7tjfaXlWWn6P6oM5o\nksOuYPuFsngA1bhiA6cBt5X2+cB5Zbme01uBMwYpzOiDpNHAe4Af1JpPJ/nrFmLnWqpfzp3dUKAd\nBTxdW99Q2qLZRtneBFUBAIwq7b3z+ReSz8aQNJbqSsyDwJHJYfOV22OPABuBe4A/Aptt7yib1M+Z\nr+TO9nZgs6TXDHLI0dO3gSupCmskHQ48m/x1DQOLymT7V5S2fjl3dnoetD3RboqOfLKheyWfDSXp\nVVT/lc+0/dwuJodODhuk/CGfIGkksBA4od1m5Xvv3InkrmMkvRfYZHuVpKmtZnbOU/LXXJNtb5R0\nBLBY0pP0nZO9Ond2wxW0DUB9IORo4K8diiX23KbWpVtJrwOeKe0bgKNr2yWfDVAGId8KLLB9Z2lO\nDruI7X8B9wOnAIeW8bvQMz+v5E7SfsBI27t6XnIMrCnAuZL+BNxEdWvzOqpbX8lfFyhXyLD9d+AO\nqmFZ/XLu7IYCbQXwRkljJO0PXAjc1eGYYme9/+u7C7i0LF9KNSlxq/0jAJJOoboVs2lwQoxd+BHw\nhO25tbbksOEkvbb1CTFJBwHvphpsfh9wftlsOj1zN70sn081gDk6xPZs28fYfj3V37Ylti8h+esK\nkkaUOw9IOhg4C1hNP507u2IeNElnA3OpCsof2p7T4ZCipj4hMbCJakLiO4BbqP5bWA+cb3tz2f56\n4GzgeeAy2ys7EHYUkqYAS6lOLC5fs4HlwC9IDhtL0jiqQcjDytfPbX9N0rFUH6g6DHgEuMT2NkkH\nAAuACcA/gAttr+tI8NGDpHcBn7V9bvLXHUqeFlKdM4cDP7U9p4wL/L/PnV1RoEVEREQMJd1wizMi\nIiJiSEmBFhEREdEwKdAiIiIiGiYFWkRERETDpECLiIiIaJgUaBERERENkwItIgaMpC3l+xhJF/Vz\n37N6rf+mP/vvb5KmS/pup+OIiO6QAi0iBlJrosVjgQ/tzY61R930ZXaPA9mn7k3/HfI/Tzy5Bz+P\niNiH5Bc+IgbDNcCpklZKmilpmKRrJT0kaZWkj0I1m7qkpZLupHpkEZIWSlohabWkK0rbNcBBpb8F\npW1L62CSvlG2f1TSB2t93yfpFklrWvv1VraZU2JbW560sNMVMEm/lPTO1rHL+/mdpMWSTi79/EHS\n+2rdH1Pa10r6cq2vi8vxVkr6niTV+v2mpEeonrEZEUPE8E4HEBFDwlWUx9gAlIJss+1J5Rm7D0ha\nXLadAJxke31Zv8z2ZkkHAisk3WZ7lqQZtt9aO4ZL3+8H3mJ7nKRRZZ/7yzbjgROBjeWYk23/tk28\n+5XYzgG+ApxZP0YbBwP32v68pNuBrwJnAG+mehTT3WW7k4GTgBdLXHcDLwAXAJNtb5d0A3Ax8JPS\n7zLbn+vzJxsR+6QUaBHRCWcB4yS1Hgg9EjgO2AYsrxVnAJ+WdF5ZHl22W76LvqcANwHYfkbSr6kK\noy2l778BSFoFjAXaFWi3l+8PA2P24P1std0qMFcDL9reIWl1r/3vqT2T7zbgVGA78Daqgk3AgVQF\nJOW124mIIScFWkR0goBP2r6nR2P1wOjne62fDkyyvVXSfVQFTKuPvvrua31rbXk7fZ8Dt7bZ5mV6\nDgs5sLa8rba8o7W/bUuqH6N+BU619Rttf7FNHP92HpgcMSRlDFpEDKRWcbQFeHWtfRHwiVbxIuk4\nSSPa7H8I8Gwpzo6n5zisl3oVP61jLQUuKOPcjgDewa6vuO3pe1gHjFflaGBim212tT/AmZIOlXQQ\ncB7wALAE+ECJFUmHlf53129E7MNyBS0iBlLr6s9jwPYy2P1G23MljQVWltt6z1AVLL39Cvi4pMeB\nJ4FltdfmAY9Jetj2h1vHsr1Q0inAo1RXs64stzpP6CO2vmLusW77AUnrgMeBNVS3P3fXV+/XllPd\nsjwKWGB7JYCkLwGLyyc1XwJmAE/vpt+I2IcpV88jIiIimiW3OCMiIiIaJgVaRERERMOkQIuIiIho\nmBRoEREREQ2TAi0iIiKiYVKgRURERDRMCrSIiIiIhvkPHqWjuuEP5PgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1bcb3b8790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A useful debugging strategy is to plot the loss as a function of\n",
    "# iteration number:\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write the LinearSVM.predict function \n",
    "y_train_pred = svm.predict(X_train)\n",
    "y_test_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#and evaluate the performance on both the test set\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.24      0.30        25\n",
      "          1       0.14      0.07      0.10        14\n",
      "          2       0.13      0.07      0.09        30\n",
      "          3       0.76      0.89      0.82       181\n",
      "\n",
      "avg / total       0.61      0.68      0.64       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        25\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00        30\n",
      "          3       0.72      1.00      0.84       181\n",
      "\n",
      "avg / total       0.52      0.72      0.61       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# compare result with the most common dummy classifier\n",
    "print classification_report(y_test, [3]*len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.386475\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = numpy.random.randn(4, X_train_sample.shape[0]) * 0.01 \n",
    "loss, grad = softmax_loss_naive(W, X_train_sample, y_train_sample, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print 'loss: %f' % loss\n",
    "print 'sanity check: %f' % (-numpy.log(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -0.000327 analytic: -0.000327, relative error: 8.012937e-09\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000621 analytic: 0.000621, relative error: 9.943626e-10\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n",
      "numerical: 0.000000 analytic: 0.000000, relative error: nan\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_train_sample, y_train_sample, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_train_sample, y_train_sample, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 1.386481e+00 computed in 0.054284s\n",
      "vectorized loss: 1.386481e+00 computed in 0.033899s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_train_sample, y_train_sample, 0.00001)\n",
    "toc = time.time()\n",
    "print 'naive loss: %e computed in %fs' % (loss_naive, toc - tic)\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_train_sample, y_train_sample, 0.00001)\n",
    "toc = time.time()\n",
    "print 'vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic)\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = numpy.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print 'Loss difference: %f' % numpy.abs(loss_naive - loss_vectorized)\n",
    "print 'Gradient difference: %f' % grad_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 500: loss 1.386206\n",
      "iteration 100 / 500: loss 1.356404\n",
      "iteration 200 / 500: loss 1.330890\n",
      "iteration 300 / 500: loss 1.309366\n",
      "iteration 400 / 500: loss 1.290849\n",
      "That took 515.802718s\n",
      "Current loss is 1.278269\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers import Softmax\n",
    "sm = Softmax()\n",
    "tic = time.time()\n",
    "loss_hist = sm.train(X_train, y_train, learning_rate=5e-2, reg=0.01,\n",
    "                      num_iters=500, verbose=True, batch_size=20000)\n",
    "\n",
    "toc = time.time()\n",
    "print 'That took %fs' % (toc - tic)\n",
    "print 'Current loss is %f' % loss_hist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f1bc9ac3750>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAHuCAYAAADJMutoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xm81mP+x/HX1aIkQrZkyq4spWRvORgTWbLP2AYNxjKG\nGWM3o5mMZRY/TDMIY4/JFlmTHGREUaIYEUooLRKFluv3x3XSQcvpdO77e3/PeT0fj/M4935/+p3H\nzO891/W9Pp8QY0SSJEn5UC/rAiRJklR1hjdJkqQcMbxJkiTliOFNkiQpRwxvkiRJOWJ4kyRJypGC\nh7cQws0hhCkhhDHLed2OIYT5IYRDKj12XAjh7RDC/0IIPy90rZIkSaUuFLrPWwihM/AFcHuMsd1S\nXlMPeAqYC/w7xvhACGEtYCTQEQjAK0DHGOOsghYsSZJUwgq+8hZjHAbMXM7LzgDuA6ZWeqw7MDjG\nOCvG+BkwGNinMFVKkiTlQ+bXvIUQNgQOAq4nrbAt0hKYVOn+5IrHJEmS6qwGWRcAXA2cF2OMIVTO\nbt8JcosscY83hOCML0mSlBsxxiXlnCophfDWCbgnpOS2DrBvCGE+8CFQVul1GwHPLO1DnNGaT717\n96Z3795Zl6Fq8u+XX/7t8s2/X759b7FqhRUrvAWWvJJGjHHTb18Uwi3AoBjjwxUHFv4cQmhG2t7d\nGzi/GMVKkiSVqoKHtxBCf9IKWvMQwkTgEmAVIMYY+33v5d8un8UYZ4YQ+pBOnEbgjxUHFyRJkuqs\ngoe3GONRK/DaXt+7fytwaw2XpBJSVlaWdQlaCf798su/Xb7596vbCt7nrRhCCLE2/DskSVLtF0JY\nqQMLmbcKkSRJUtUZ3iRJknLE8CZJkpQjhjdJkqQcMbxJkiTliOFNkiQpRwxvkiRJOWJ4kyRJyhHD\nmyRJUo4Y3iRJknLE8CZJkpQjhjdJkqQcMbxJkiTliOFNkiQpRwxvkiRJOWJ4kyRJyhHDmyRJUo4Y\n3iRJknLE8CZJkpQjhjdJkqQcMbxJkiTliOFNkiQpRwxvkiRJOWJ4kyRJyhHDmyRJUo4Y3iRJknLE\n8CZJkpQjhjdJkqQcMbxJkiTliOFNkiQpRwxvkiRJOWJ4kyRJyhHDmyRJUo4Y3iRJknLE8CZJkpQj\nhjdJkqQcMbxJkiTliOFNkiQpRwxvkiRJOVJrwtu550KMWVchSZJUWLUmvD3/PJxwAsyfn3UlkiRJ\nhVNrwtuQITB1Khx8MMyZk3U1kiRJhVFrwttqq8FDD8Gaa8JPfgIzZ2ZdkSRJUs2rNeENoGFDuO02\n2Hln6NoVJk/OuiJJkqSaVavCG0C9evC3v8Gxx0LnzvC//2VdkSRJUs1pkHUBhRBCOn26zjpQVgYP\nPww77ph1VZIkSSuv1q28VdarF9xwA+y3Hzz1VNbVSJIkrbxaHd4ADjwQ7r8fjjkG/vOfrKuRJEla\nObVy2/T7unRJK289esCnn8KvfpV1RZIkSdVTJ8IbQLt2qZFv9+4pwPXuna6NkyRJypMQa8FMqRBC\nrOq/Y+rUtAK3xRbwr3/BWmsVuDhJkqRKQgjEGKu9hFTrr3n7vvXWg+eeg+bNYZddYOLErCuSJEmq\nujoX3gCaNIG+feHUU1MvuLfeyroiSZKkqqkz17wtyVlnwdprwx57wKBB0KlT1hVJkiQtW8FX3kII\nN4cQpoQQxizl+QNDCK+FEEaFEF4OIexe6bkrQwhvhBDGhhCuLkR9P/956gXXowc880whvkGSJKnm\nFGPb9Bag+zKeHxJjbB9j7AD8ArgJIISwK7BbjHFbYFtgpxBC10IUeOCBMGAA/PSnabi9JElSqSr4\ntmmMcVgIofUynp9T6W5TYOGip4DGIYTGpJDZAJhSqDrLyuDxx2H//eGzz+C44wr1TZIkSdVXEte8\nhRAOAi4H1gX2A4gxDg8hlAMfV7ysb4yxoGPmd9ghbZ127w6TJsFFF9kLTpIklZaSCG8xxoHAwBBC\nZ+BSYO8QwmZAG2BDIABDQghPxhiHLekzevfu/e3tsrIyysrKqlVLmzYwfDgcfDB89BH8858GOEmS\nVH3l5eWUl5fX2OcVpUlvxbbpoBhjuyq8dgLQCegFNIox/rni8d8Dc2OMf1vCe6rcpLeqPv88baXu\nuiv89a+pvYgkSdLKykuT3lDx88Mn0grbotsdgYYxxhnARKBbCKF+CKEh0A14sxjFAqyxBgwZAjNm\npF5w06YV65slSZKWrhitQvoD/wW2DCFMDCGcEEL4ZQjh5IqXHFrRDuRV4B/AERWP3wdMAF4HRgGj\nYoyPFrreytZeG/r3h333hW7d4OOPl/8eSZKkQqpzs02r67LL4KabUksRm/lKkqTqWtltU8PbCrj3\nXjjtNLjtttTUV5IkaUXl5Zq3WuHww9MYreOPh+uug1qQeyVJUs648lYN//sfHHFEug7u6quhnhFY\nkiRVkdumFD+8AcyaBQccAI0awS23wEYbFfXrJUlSTrltmpFmzWDoUNh9d9hrL1uJSJKk4jC8rYQG\nDaB373QtXOfO8GbRutBJkqS6qiTGY+XdpZfCxhvDT34Cr72W+sNJkiQVgte81aDf/AZefz21EmnZ\nMutqJElSKfKatxJy5ZWw887Qvj385S+wcGHWFUmSpNrGlbcCePddOOYY6NAB+va1lYgkSVrMViGU\nXngD+PzzNIVhww1TK5HVVsu6IkmSVArcNi1Ra6wBQ4ZA06bQsWO6Fk6SJGllufJWBHfcAb/7HTz6\nqEPtJUmq61Z25c1WIUVw7LGw+uppIsPzz8Pmm2ddkSRJyiu3TYvkoIOgTx/YdVe46aasq5EkSXnl\ntmmRjRsHBx4IRx8N557rQQZJkuoaDyzkzNZbw7PPpkkMm28Ob7yRdUWSJClPXHnLUP/+afXt+edh\nk02yrkaSJBWDBxZy7KijYNYs2Htv+Pe/oUsXCNX+U0qSpLrA8JaxU09NJ1F79UoTGW68EdZcM+uq\nJElSqXLbtER89RWcdhpMmwYPPeQKnCRJtZUHFmqJxo3h+uvhww/hootg7tysK5IkSaXI8FZCVlkF\nBg6Et96CnXaCKVOyrkiSJJUaw1uJadUK7r8fDjsM9toLZs7MuiJJklRKDG8lKAS45JJ0CnWPPaBv\nX8j5JX2SJKmGeGChhC1cmLZRzz0X+vWDPffMuiJJkrSyVvbAguEtB267DW6/HQYPhvr1s65GkiSt\nDE+b1gFHHQVffglNm6bxWkOHZl2RJEnKiitvOTJnDjz8cGolMnZsai8iSZLyxZW3OqRJE/jZz6BT\np7QCd9NNWVckSZKKzZW3HJo/H156CQ48EN5+G5o3z7oiSZJUVR5YoO6Ft0VOOQXGjYMePeC88xyp\nJUlSHhjeqLvh7bPPUkPff/4TDj4Yzj8fGjbMuipJkrQshjfqbnhb5MMP4fDDYeJEGDECNtww64ok\nSdLSGN4wvC1y4YUweXLqCydJkkqT4Q3D2yKzZ8M226SZqMccA926QYMGWVclSZIqs1WIvrX66jB6\nNGyxBZx9NvTsCV99lXVVkiSpJrnyVkvNm5cmMzRqBHfemXU1kiRpEbdNMbwtzZw5sMMO8NOfwrHH\nwqab2k5EkqSsuW2qpWrSBB58ECZMgC5dYNdd4Ztvsq5KkiStDFfe6ogYYf/9Yeed4YgjoE2brCuS\nJKluctsUw1tVvfNOOok6cybcc0+azCBJkorL8IbhbUUNGpTGaY0eDausknU1kiTVLV7zphW2//7Q\nrh106gT/+1/W1UiSpBVheKuDQoC7706D7ffdF554AqZNy7oqSZJUFW6b1nHXXgv33guffgrDh8Oa\na2ZdkSRJtZvXvGF4qwm//nUKb3fdlSY0SJKkwvCaN9WIq6+Go4+GsjKYNSvraiRJ0tK48qbvOPHE\n9Pvvf4dmzbKtRZKk2siVN9WoK6+Ejz+G1q3TgQYPMkiSVFoMb/qO5s3h0UdTQ9/GjaF9e9uJSJJU\nStw21TL99a/w7LNw440wbx60apV1RZIk5ZunTTG8FdLXX8PWW6eRWvXrp9moN90EG2yQdWWSJOWT\n17ypoBo1gqefhrffho8+gm23hQMPTIPuJUlS8bnyphWycCG0aQM33wxdumRdjSRJ+VPSK28hhJtD\nCFNCCGOW8vyBIYTXQgijQggvhxB2r/Tcj0IIT4YQxoUQ3ggheLVVCahXD846Cy64AMaOzboaSZLq\nnkJvm94CdF/G80NijO1jjB2AXwA3VXruduDKGOPWwE7A1MKVqRXRqxfssUdq6Pvcc1lXI0lS3VLQ\n8BZjHAbMXMbzcyrdbQosBAghtAXqxxiHLnpdjPGrQtaqqmvcGPr0gTvvhAMOSCdQX3wx66okSaob\nMj+wEEI4KITwJjAI6FXx8JbArBDC/SGEV0IIV4YQqr03rMLo3h3GjIGLLoLTT4cFC7KuSJKk2q9B\n1gXEGAcCA0MInYFLgb1JdXUGtgcmAQOA40nbsEvUu3fvb2+XlZVRVlZWqJJVSevWcPLJcN990LUr\n/PGPsNdeYNSWJCkpLy+nvLy8xj6v4KdNQwitgUExxnZVeO0EoBOwBXB5jHHPisePAXaOMZ6xlPd5\n2jRjCxbAPfek8HbooXD55VlXJElSaSrp06YVQsXPD58IYbNKtzsCDWOMM4ARwFohhOYVT+8JjCt0\noaq++vXh6KNh2LA0jWH8+KwrkiSpdirotmkIoT9QBjQPIUwELgFWAWKMsR9waAjh58A3wFzgCNKT\nC0MIvwOGVlzq9gpwYyFrVc1Ybz04/3w47DDo2xe23BLWXz/rqiRJqj1s0qsaFyP06wfXXQeTJsEz\nz0C75W6aS5JUNzjbFMNbKbvzTvjDH+DRR6Ft26yrkSQpeysb3jI/bara7Zhj0nD7Ll3ghBPg4ouh\nWbOsq5IkKb8y7/Om2u8Xv4BXXoEZM2CnneCDD7KuSJKk/HLbVEX1pz/BCy/ASSelE6oHH5x1RZIk\nFZfXvGF4y5N586BjR5g6NY3ZevddaODmvSSpDslDnzfpWw0bwuOPw+uvw49+BAMHZl2RJEn54sqb\nMjNwIJx7Lrz0Eqy1VtbVSJJUHK68KbcOOgj23x+22AJatIB//Sv1iJMkSUvnypsytXBhGqU1Zw70\n6gX77guXXZZ1VZIkFY4HFjC81RbTpkFZGRx5JFx0UdbVSJJUGIY3DG+1yccfwx57wDrrwN/+Brvs\nknVFkiTVLK95U63SogWMGQOnnAI9e8Lo0VlXJElSaTG8qeSsskoaq9W3L+y9N1x1VdYVSZJUOtw2\nVUmbPDnNRd1zT1hzTbj88tQrTpKkvHLbVLVay5bwxBOw0Uapse8pp9hORJJUt7nyptz48st0gOGc\nc+CII9J4LUmS8saVN9UZq60Gd94Jp50GTZvCj38M77yTdVWSJBWX4U250r49TJoEs2dDjx6prci7\n72ZdlSRJxeO2qXKtd294/3249daMC5EkqYps0ovhrS779NM0G3XEiHQKdeONs65IkqRl85o31Wnr\nrpvmoW63HXTqlE6mSpJUm7nyptz75BP4/PM0G/Xgg+Hqq9N8VEmSSpHbphjetNjYsamp78iRcPbZ\ncMUVsNVWWVclSdJihjcMb/qu3/4W7r033d5wQ3jhBWjQINuaJElaxGvepO855xxYdVV4/vnUG+6G\nG7KuSJKkmuPKm2q1UaNSP7jx41NjX0mSsubKm7QMHTrAAQfAfvultiKSJOWd4U213nXXwQ47QM+e\n8PXX6bHx4+GkkxxyL0nKH7dNVScsXAiHHppOoW60EUyeDDNmwIsvph5xkiQVi6dNMbypaubPT3NQ\nP/4YvvoKHnsMWrSACy7IujJJUl1ieMPwpuoZPDjNRv3vf7OuRJJUl3hgQaqmbt3S9ulOO8EHH2Rd\njSRJVePKm+q0efPgT3+CV15JYa5jR9h776yrkiTVZm6bYnjTyvnmG9h5Z2jZEkaMSE19Dzoo66ok\nSbWV4Q3Dm1ZejBBCWoHbZx94+mnYdts09H7DDbOuTpJUmxjeMLypZt1zD/zqV9CqVTqdOnEiNGuW\ndVWSpNrC8IbhTTVv/HgYMwYGDEgHGs4+O+uKJEm1heENw5sKZ+TIdP3byy/DbbfBCSfABhtkXZUk\nKc9WNrw1qMlipNqmUyfo1Qs23xxWXTVdA3fNNVlXJUmqy1x5k5YjRnjqKWjbFtq3h6uugu7d03QG\nSZJWlNumGN5UPHfcAQMHplOpTz0FrVvDe+/BVlul5+fPhwauZ0uSlsHwhuFNxffPf0K/frDXXul0\n6uTJqV9cmzbw+OPptyRJS+J4LCkDp50GP/oR3HorNGwIo0bBoEHw/vspvEmSVCiuvEnVNH16mol6\n552w5prw0ktpy3TePHjssayrkySVKk+bShlp3jz9fPYZHHAArL8+PPccbL01fP01NGqUdYWSpNrI\nbVNpJXXrlnrAjRsHG20E22+fJjIMHJh1ZZKk2shtU6mGLVgAt98ODz1kgJMk/ZCnTTG8qfTMmAEb\nb5ya+jZpknU1kqRSYnjD8KbStNde8OMfp95vX34JV1yRdUWSpFJgeMPwptL0/PMpsDVrltqHvPmm\nc1ElSYY3wPCm0nfiidC4cRqxddppEKr9H1lJUt4Z3jC8qfS9+ir07Jn6wPXpA8ccAwsXQj3Pe0tS\nnWN4w/Cm/BgxIvWEe/NNOPDAFOJ++cusq5IkFZPhDcOb8uXEE2H8+DSd4YsvYPhw2GwziNGVOEmq\nCwxvGN6UL5MnwxZbwA03wFdfwfnnQ9OmsPPOMGBA1tVJkgqt5MNbCOFmYH9gSoyx3RKePxDoAywE\n5gG/iTG+UOn51YE3gQdijL9eyncY3pQr77wDm26aVto+/DD9dO+eVuPWXDPr6iRJhZSH8NYZ+AK4\nfSnhrUmMcU7F7e2AATHGtpWevxpYB5hheFNtdvDB0KNHOtiw3npZVyNJKpSVDW8Fv8ImxjgMmLmM\n5+dUutuUtAIHQAhhB2A9YHDBCpRKxDHHwMknw1ZbpWH3kiQtSVGueQshtAYGLWnlreL5g4DLgXWB\n/WKML4UQAjAUOAb4MbCDK2+qzWKEmTPhrLOgRQtYdVXYdls45BAPMkhSbbKyK28NarKY6ooxDgQG\nVmyxXgrsDZwGPBpjnJxyHMv8R/bu3fvb22VlZZSVlRWqXKkgQoC1104HGLbbDo4+Gu69Fz76CH69\nxP/ZIknKg/LycsrLy2vs80pi5e17r50AdAKuBTqTtlFXBxoC/4oxXriE97jyplpl2jRYZx0YNw66\ndYPRo6Fly6yrkiTVhLysvAWWsnIWQtgsxvhuxe2OQMMY4wzSdumi1xxH2jb9QXCTaqN11km/t94a\nzjsPOnRIo7VatIBLL4XNN8+2PklSdgoe3kII/YEyoHkIYSJwCbAKEGOM/YBDQwg/B74B5gJHFLom\nKU9+9zvYb7/UH27YsHQa9Y03nI8qSXWVTXqlHIkRtt8errgC9t47zUqVJOVLybcKkVRzQkgrcYcf\nDo0awZZbpuvjJEl1h+FNypmjj4YXX0yjtbp1g7//PT1+7rnwr39lW5skqfDcNpVy7P33oWNHeOQR\n2H//tBp3112w555ZVyZJWpqCb5uGELYMITwdQnij4n67EMLF1f1CSTVn443h97+Hrl3h+OPhn/9M\np1NfeQWuuSbr6iRJhbDclbcQwrPAOcANMcYOFY+9EWPctgj1VYkrb6rr7r4b9tortRjZdluYMiUd\nbvj0U6hfP+vqJEmVFePAQpMY48vfe2x+db9QUs078sg0zL5ePbj88jQjtUWLtAIH8PTTaVKDJCn/\nqtJoYFoIYTMgAoQQDgM+LmhVkqqtZ8/089VX8NRT0LRpmo8aAjzzTGr4K0nKr6psm24K9AN2A2YC\n7wHHxBjfL3h1VeS2qfRDjz0GF1yQ2om0bw9z58L8+XDllVlXJkl128pum1b5tGkIYTWgXoxxdnW/\nrFAMb9IPzZuX2of07w9vvplOpv70p/D2205nkKQsFTy8hRD+sKTHY4x/qu6X1jTDm7R0MaawFiNs\nuilcfDEcc0xqKyJJKr5iHFj4stLPAmBfYOPqfqGk4lq0yhYC9OsHt94KBxwAX3+daVmSpGpa4Sa9\nIYRGwOAYY7fClLTiXHmTqm7+/LR9+s03MGAArLpq1hVJUt2SxWzTJkDL6n6hpGw1aAD33AOrr55a\njFT+3z2vvZbu/+UvMHx4djVKkpauKte8vU5FmxCgPrAu8KcYY98C11ZlrrxJK+6bb9JorV69oFWr\n1FakXz+4/no466x0XdyNN2ZdpSTVPsU4sNC60t35wJQYY0k16TW8SdUzciT89rdpMsPmm8MOO8BR\nR8Euu6TTqR9+6MlUSappBQtvIYS1l/XGGOOM6n5pTTO8STUjxrQSd9ZZcNhh6Zo4m/pKUs0qZHh7\nj7RduqQPjzHGTav7pTXN8CbVvIsuSuGtb1/o3j3raiSp9ihak95SZniTal6M6Rq4+++HwYOzrkaS\nao+ihLcQwlrAFkDjRY/FGJ+r7pfWNMObVBjTp8Mmm8CMGemUKsCoUbD99l4LJ0nVVfBWISGEE4Hn\ngCeBP1b87l3dL5SUH82bw0Ybweuvp/vl5emE6jvvZFqWJNVpVenzdiawI/BBjHEPoAPwWUGrklQy\ndt8d7r4brrgCTjsthbnnn8+6Kkmqu6oS3r6KMX4FabpCjPEtYKvCliWpVHTtCtdeCxMnwi9+ARde\naHiTpCxVpc/bg8AJwFnAnsBMoGGMsUfhy6sar3mTCmf+/HTt2/rrp/tjx8KBB8K778LTT8NHH0GP\nHmmLVZK0fEU9bRpC6AY0A56IMX5T3S+taYY3qXgWLoT11oPNNlt8oGGNNdKpVEnS8hVjwsI1wH9i\njP+t7pcUmuFNKq7XX4epU2G33WDBAth4Y7jlFpg7F444IuvqJKm0FSO8HQf8FNgSeJAU5EZW9wsL\nwfAmZeucc+C666BhwzRSa7XVYNIkeOEFOOggaNx4+Z8hSXVF0bZNK8ZlHQr8DGgVY9yiul9a0wxv\nUrbmzEm94E45Ja28HXpoGnbfqFE67HDYYVlXKEmlY2XDW4MVeO3mQBtgY2Bcdb9QUu3TpEn6OeEE\n+L//g/r1YeedYe+9YcgQw5sk1aSqbJteCRwCvAv8B3gwxlhSfd5ceZNKw7x5sMsuqa3I1VdDu3Zw\n8MGpqe/dd8Mnn8BvfpN1lZKUrWKsvL0H7BpjnFbdL5FUNzRsCHfcAYcfDj17pmvfvvgi9YU788w0\nL3X33WGnnbKuVJLyy8H0kgrqssvSz8knQ4cOadi9TX4l1WVF7fNWqgxvUmmbNy9dB7dgQTrI8PTT\nsPXWWVclSdko+GB6SVpZDRtCvXrp9wknwA03ZF2RJOXXcsNbCGGzEEKjittlIYRfhxDWLHxpkmqj\nU0+Fhx+GM85IK3K9e8PHH2ddlSTlR1VOm44GOpFahDwGPARs42xTSdU1a1aajzp1arrdujWUl6e+\ncJJU2xVj23RhjHE+cDDwjxjjOUCL6n6hJDVrBgMHwl57wRtvpNmot9ySnrv+erjggu++/quvil+j\nJJWqqrQKmRdCOBI4Djig4rGGhStJUl2w1lrQt2+6fc45qf/bKqukk6mrrpqeP/VU+Owz2HZbGDYM\nttsu25olqRRUZdt0a+AU4MUY490hhE2An8YYryhGgVXhtqmUbzFC27ZpsP3gwemxs86C116D9u1h\n7Ni0SrdodU6S8qyorUJCCGsBP4oxjqnuFxaC4U3Kv7FjoXlz2GCDxY898EBalXvySdhxRxgzBn70\no+xqlKSaUPDwFkIoBw4kbbG+AkwFXogx/ra6X1rTDG9S7XfRRfD++3DXXVlXIkkrpxgHFprFGD8n\nzTe9Pca4M/Dj6n6hJFXHBRfAc8/B8OFZVyJJ2apKeGsQQmgBHAE8UuB6JGmJmjaFc8+Fv/8960ok\nKVtVCW9/Ap4E3o0xjgghbAqML2xZkvRDxx8PQ4fCBx+kBr8zZmRdkSQVn7NNJeXK+efDJ5/Aaqul\nbdQnn4Q770wHG0KAt9+GTTeFBlVphCRJGSjGgYWNgH8AuwMRGAacGWP8sLpfWtMMb1LdMXt2Gmo/\nfz5svDFMmJCmNAwaBD/+cRp836dPWqWTpFJUjPD2FNAfuKPioWOAo2OMe1f3S2ua4U2qW557Dr75\nBtZfH26+GXbdFf7yF7j7bthqqxTinnoq6yolacmKEd5Gxxi3X95jWTK8SXXbwoXQrl1akYsRhgyB\nceOghYP8JJWgYrQKmRZCOCaEUL/i5xhgenW/UJJqWr16aSLDvfdCjx7Qsyfcc0+am/rcc1lXJ0k1\nqyorb62AvsCupGve/gv8OsY4sfDlVY0rb5LmzoWddoLHHoO33kp94Zo1g3fegfHj09xUSSoFRR2P\nVelLz4oxXl3dL61phjdJkLZMQ4AFC9IYrXr1YIstoGNH2H33tCJXv37WVUqq67IKbxNjjK2q+6U1\nzfAm6fuuuCLNSt1xR/jzn2HyZPjsMzjzTDj55BTyJCkLWYW3STHGkhkPbXiTtDwxpga/550HXbrA\naafB5psb4iQVXzEOLCyJSUlSroQAe+0FgwfD2LHQuXNq+AtpVW7kyGzrk6SqWmoP8hDCbJYc0gKw\nasEqkqQCWnvtFOCmT09bqu3awV13wX//C6NGwSabZF2hJC1bQcdjhRBuBvYHpsQY2y3h+QOBPsBC\nYB7wmxjjCyGE9sB1wOrAAuCyGOOAZXyP26aSVtgbb0DXrinQ9eoFw4fDww9nXZWk2i6Ta96q/OEh\ndAa+AG5fSnhrEmOcU3F7O2BAjLFtCGELYGGM8d0QQgvgFaBNjPHzpXyP4U1StZSXpzYibdum0VrT\np9tWRFJhrWx4K+jo5hjjsBBC62U8P6fS3aakFThijOMrvebjEMJUYF1gieFNkqqrrGzx7S23hJdf\nTtfDfV+M6adeda8UlqQakvl/DYUQDgohvAkMAnot4fmdgIYxxneLXpykOmWPPeCZZ9LtGNMBhwcf\nTPcvvRQuvji72iRpkYKuvFVFjHEgMLBii/VS4NuB9xVbprcDxy7vc3r37v3t7bKyMsoq/89pSaqC\nsjL4wx8aHEXRAAAgAElEQVTg2GPh/ffTZIaTT4YNNoB//APWWw8uuyzrKiXlTXl5OeXl5TX2eQW9\n5g2gYtt00JKueVvCaycAnWKMM0IIqwPlwJ9jjA8s531e8yZppX39deoDd+edqcHvr3+dhtsfc0w6\nmTpmTBq9tf76WVcqKc+y6vO2IkLFzw+fCGGzSrc7krZHZ4QQGgIDgduWF9wkqaY0agRXXw0jRqTr\n3o49Fg45BPr2TVMaunZNBxwkKUuFPm3aHygDmgNTgEuAVYAYY+wXQjgX+DnwDTAX+F2M8cUQwtHA\nv4GxpOAXgeNjjGOW8j2uvEkquGuugUcegXvvhSZNoHfvdB1ckyZZVyYpT0q6VUixGN4kFcOXX8LZ\nZ6fVt1/8Ai68EE4/Pa3WSVJV5WHbVJJqhdVWg+uvT7NRzz03rcLdd9/iE6qSVAyuvEnSCpozBx57\nDA47LP0+/XR49VVYa62sK5OUB668SVKRNWmSghtAjx5wxBHpMMPHH6fHnnrKnnCSCseVN0laSTHC\nRRel1bf77oNtt4VZs+DTT6FB5t00JZUaV94kKWMhwB//CFOnQuvW8JOfpN8vvZR1ZZJqI1feJKmG\nfPIJzJ4NW2yRmv1+/TV07w777pt1ZZJKia1CMLxJKj3l5Wk2arNm8Pe/w2uvpdFba6+ddWWSsmZ4\nw/AmqfTEmK55mzAhTWtYbTW44440XmvjjdMhB0l1k+ENw5uk0vbJJ3DttWn81oMPwrRpcNppaWJD\n165pYoOkusMDC5JU4jbYALbfHp5/HsaPhw4d4NZbYcCA9Fhl8+dnUqKkHDG8SVIRdOgATz+dQlz/\n/jBiRFp1mzsXpk9f/LpddoFnn82uTkmlz/AmSUWw2WbQtCnsuiusvno6yBACbL01jBuXXjNzJrzy\nCtx+e7ofY/qRpMoMb5JUBPXqwQ47wO67f/fxbbZJs1G33x6efDKFuYEDU5uRq6+GXr3S677+uvg1\nSypN9v6WpCIZOBDWWOO7j229NfTuDV98AeecAyeckK6DGzQoXRM3ahR8+WU6tTpyZCZlSyoxrrxJ\nUpGsuWZagatsm21SY98//xk+/DCtzJ18Mlx2Gbz5JvTtmx4fNy6FOEmyVYgkZWj69DQX9brr4Le/\nhT59YJVV0nit3XaD++9Pr9tpp9Tsd/p06NkzXS8nKZ/s84bhTVLtc9ddsOGGsMce6f7pp6f+cAMG\nwBtvpBU7Sfm0suHNa94kqQQdffR37++4Y7oebo01YPBgw5tUl3nNmyTlwE47QcOGcOWVKbxJqrvc\nNpWknPjgg7Ty1qoVTJ0Kq66adUWSqsNr3jC8SapbDjssBbirrsq6EknVYXjD8CapbpkxIzX83XVX\nuOQSeO659Nh552VdmaSq8MCCJNUxa68Nr74K/fqldiJNm8KcOXDggWkM19ChsM8+333PQw+lKQ1H\nHJFNzZJqjitvkpRj772XDjLcd1/qFbfeejBsGIwfn366dEnhbu+9oUEDePzxH37GtGnQvLm946Ri\ncdsUw5skxQhPPAFvv51+Zs6E//wHzj47NQFu2TKFtxkzfjjlYeut0ySHPffMpnaprnHbVJJECLDv\nvulnxIjUWuSss+Df/05bql26wDvvpDFb2267+H2TJ6cxXK+8YniT8sI+b5JUy3TqBJdfDpdemlbf\nRo2CY49Nc1NfeOG7r33mGWjUKL1GUj64bSpJdcRtt8Gf/wxXXw09eqTHevVK26nPP59W4CQVnte8\nYXiTpKpYuBAGDYJTToFbboHOnWHLLdO1cjvvnA4urLZa1lVKtZ/XvEmSqqRePejZE9ZdN/3eaivo\n3h3atYO2beH112GXXbKuUtLyeM2bJNUxu+2WtknbtIFrr02P7btv2k6VVPrcNpUkMXcudOgARx8N\n55wDjRtnXZFUe63stqkrb5IkVl0VHn00jdo6/fSsq5G0LK68SZK+NWVKuhbuuefgnnugT5/U2Hfd\ndbOuTKo9PG2K4U2SatIBB6QRW40bw6abwvDhqcHvJptkXZlUO7htKkmqUaefDt26wejR6fTpoYfC\n/fenPnBffw0TJtjUV8qSK2+SpGV66qkU6D76KDX5HToUhgyBP/4Rfve7rKuT8seVN0lSQZWVwWef\nwUEHwTXXpOvhBg6E/v3T3NT778+6QqlusUmvJGmZGjaEt9+GZs3SRIZDDoGuXdNj/fvDaafB9Omw\n+upZVyrVDa68SZKWa801IQS49Va45JI0zH777dNpVEhbqwDffANHHgkvvphZqVKtZ3iTJFXZ7rtD\nq1bp9m67wcSJcPbZ8Mgj6bHTT0/zUxfdl1TzDG+SpGrp1i2dRj3ppBTY/vY3KC9PQ++HD0+vuece\nx25JNc3TppKkaokxjdVq0gT+/e/FK3Bt28LGG8P118MZZ8Baa8HIkXDiidCxI5x3HtSvn3X1UnZs\n0ovhTZJKwcKFUK9iP6dNG/jwQ3jmmTT0/re/hccegwUL4OCD4dxzs61VytLKhjdPm0qSakS9Shfi\ndO2aVtd23BG6dIErroC+fdNW6447wk9+kg48SFpxrrxJkmrcV1/BKqukQHf11amZ79SpsPbacOed\nKcyNHJlGcEl1jU16JUklp3HjxStx++8Pv/pVCm4ARx8NLVrAAw+k+++9By+9lE2dUh658iZJKrob\nb0xjtu6+G44/Hl54Ad56y4MMqhtceZMk5c7++8OTT8Ls2fDQQ2mKw8MPZ12VlA+uvEmSMrHjjrDB\nBqndyOmnpxOo5eXQsuUPX7twYfpp4DE71QKuvEmScqlfP9hsM7jwwtQ+5KST0gSHhx+Gm25KbUWG\nDoXBg6Fz5zRDVZIrb5KkEnL//Wle6mefwfnnw8UXp4a/nTvD7bfDmDGw0UZZVymtHPu8SZJqjUMP\nTT9PPAH77QfHHZemN0A6vbr99rDDDul6ucpmzoTVV3dbVXWDK2+SpJITY7oO7pxzYJNN0mOzZ8O4\ncanB73vvLW49AukAxH77wamnZlOvtCIcj4XhTZLqkgMPTNuoDz8MQ4aknnIbbZRGcg0ZknV10vKV\n/IGFEMLNIYQpIYQxS3n+wBDCayGEUSGEl0MIu1d67rgQwtshhP+FEH5e6FolSaWvR490PdyIEfD0\n02nLdNasdH/69Kyrkwqv4CtvIYTOwBfA7THGdkt4vkmMcU7F7e2AATHGtiGEtYCRQEcgAK8AHWOM\ns5bwGa68SVId8fHHcOaZ0LEjvPsuHHtsCnMtWkDbtunAw/vvw/XXw5VXpi3YUO01DqnmlfyBhRjj\nsBBC62U8P6fS3abAworb3YHBi8JaCGEwsA/wn0LVKkkqfS1awIABKbjtthtst136Of98OPzwFNYa\nN4Zrr02PdeqUJjhssAFMmADrrpsON0h5VRJ93kIIB4UQ3gQGAb0qHm4JTKr0sskVj0mSxGabpdDW\npw9su2062PDAA2nFrX//dPL0r39Nge2OO+DTT1Mfub/+NevKpZVTEoeqY4wDgYEVW6yXAnuTtkp/\n8NKlfUbv3r2/vV1WVkZZWVnNFilJKjm33ALt26ctVIBWrWDPPeG55+CEE+Caa9IBhxtuSAccttsu\n9ZL705+yrVt1S3l5OeXl5TX2eUU5bVqxbTpoSde8LeG1E4BOwE+AshjjKRWPXw88E2P8wbap17xJ\nUt31+eewxhqL748dCyNHpq3RQw9NjX0vugi6dEnXym2ySTro0KZNdjWrbstFq5AQwsak8LbdEp7b\nLMb4bsXtjsBDMcYffe/AQr2K2zvEGD9bwmcY3iRJ3zF9ejrM8Oij3z2wcPbZafVtu+3SyVV7w6nY\nSj68hRD6A2VAc2AKcAmwChBjjP1CCOcCPwe+AeYCv4sxvljx3uOBi0jbpZfGGG9fyncY3iRJVTJ/\nPrz5ZjrwcM45qenvggXpWjmpGEo+vBWD4U2SVB3jx8Pf/w533ZXaizRvnnVFqgtKvkmvJEmlaost\n0orbNtuk1TgpDwxvkqQ6r02b74Y3N3NUygxvkqQ6r21beOstmDYtBbczzoCzzkq3X3gBevbMukJp\nsZLo8yZJUpbatoXHH08rcFdema6BW3/99Pgrr6Tn5s6FVVfNulLJAwuSJDF+PGy5JWy6KUyeDHvs\nAX/7W/q9YEHqGXf77dC1a9aVqjbwwIIkSStpk03Sqtptt8Euu8BJJ6VDDIcckkLdoYfCsGFZVykl\nrrxJkgR88kkaXr9wIdSrWNqYOxdmzIARI9KIrccfz7ZG1Q6uvEmSVAM22CD9rlfp/zOuuiq0bJlG\na734YgpzL7+c5qa+9156zezZMGUKvPpqmuggFZrhTZKk5WjeHDp2hDvvhH32gQ8+gBtvTM9dfnm6\nNu73v4d77oE5cxa/b9KkNNFBqkmGN0mSquCQQ9Jg+yOOgGuuSUFu4UJ48sn0e8SIdFr11VcXv6dn\nT7j22nTbq3tUUwxvkiRVwcEHp5B29tlpqH3z5ukE6rvvQnk5PPIIdOsGL72UXv/ll/DGG9C3Lxx1\nVGpBUtmoUUX/J6iWMLxJklQFLVuma9u22CLdv/xyOPlkKCtL18vttFM6qTp8eHp+5EjYYQdYd114\n5hl4+unFnzVxYnpu5syi/zNUC9ikV5KkKmrWbPHtffaBq65KbUYW2XXXNJ3hggugceMU5s49F776\nCjp0WHyS9eWX0zbqiy9Cjx7F/3co31x5kySpmn71K9hvv8X3N9sMBg1K26WXXprCW4sWKeCtvTa8\n/XZ63YgRsMYa9o5T9RjeJEmqQZ07w3/+A0cfnU6hLrLzzouvh3v55dQI+PvhbfjwtMUqLYtNeiVJ\nKoKrr06HFP79b1hrLXj99TTFYdKkdH/aNGjXLo3ievPN7/abU+1ik15JknLg2GPhiSfSNXCtW6ef\nU0+FvfaC6dPhl7+EI4+Epk3hsceyrlalzJU3SZKK5JZb4I9/hCFDYPPN06GF88+HO+5IrUdGjIC7\n7kq94wYM+O57p06FddZxRa42cOVNkqScOOGE1Bdu883T/RDgiivSdIYBA9IJ1XbtYPz4H753n32+\nO1t19OjFDYBVtxjeJEkqovr1v3s/hLR92rZtur/JJovnpi5cmLZTZ82CMWO+e8Dhd79L19Gp7rHP\nmyRJJaR58xTaZs6Ejz+Gfv2gVau0Xfrii+k1zz+fAt706emnefNsa1ZxufImSVIJCWHx6ttLL6X7\nV12VZqq+8grMmwe33pp6zHXsmCY5qG4xvEmSVGIWhbfhw9MJ1BkzYO+90wnVUaPg4YfhkEOgU6fF\n4W327MXvf/vttCKn2snwJklSidlkE5gwIa28/epXaa7qrrvCwQen5r+LWo3suGMKbx99lOarvv9+\nWpnr0QOuuSbrf4UKxWveJEkqMZtuCs8+m06dduwI77yTTqL27p2ug9thh/S6rl3h9NPhzDPh669T\ni5GFC9MqnKO3ai/7vEmSVGIeeQQOOAD+8IfUF25ZbrwxnUjt3TsFtjfegDvvhJ4909brF1/Axhun\n137+eZqpqmytbJ83w5skSSVm9mx49FH46U/TgYVliRHGjYP11oP114fDD0+zVdu3T1uoa60FL7yQ\nVu/atYMpU9IILmXHJr2SJNUyq68OP/vZ8oMbpNdssw2suy789rdw2WXp8c6dU3uRsWNTYOvXD+bO\nhZdfLmztKjxX3iRJqoWmToX581Oga98+NfTdddd0QnXYMLjwQujSJb22KiFRNWdlV948sCBJUi20\n3nrp9yGHwFFHwbnnpoMOZ5+dTqd++WVa4evaNc1XVX648iZJUi22cGFahdtggxTaWraEPn3gttvS\n4YVp01Jbku+P7VLheM2bJElaqnr1UnAD2HBD6NULTj4Zhg5NY7bWXReGDIEFC2DSpGxrVdW48iZJ\nUh12883Qvz8cdBBceilMngwNKl1U9dBD0KYNbLVVdjXWNq68SZKkajvuuNT49/zzUyPgZ55J7Ucm\nTEitRk49NQU8lQ5X3iRJquOefRaefjr1hHvwwRTmJk+Gbt3SiK6ttoIXX1z6+19+GbbcEtZcs3g1\n55lNejG8SZJUEz7+OE126NMHtt02nU7t0ye1G3nvvXT4YdH1c5Xttlua8nDcccWvOY9sFSJJkmpE\nixZp0P0ib78NzZrBrbemINeqVZrWUFmM8NZbaQ6risNr3iRJ0hKtuWZq4LvPPqnB76RJMGpUmpf6\nr3+l13z6KcycmYKeisNtU0mStEwxphB32WXw5JPpNOrQoTBxYtpO3X9/2HRTGD0660rzwW1TSZJU\nUIvGZ515JjRsCLNmQdOm6aDDnDnQvTs8/vjikKfCcuVNkiStsH/8A8aMSSGuZUv429/glVfSbS2b\nfd4kSVLRdeuWtk5HjkxNfLfccunXvb31VprgoJpheJMkSSts223TSdTVVkutQrbaCsaO/eHrvvgC\nOnSAPfeE//s/mDGj+LXWNoY3SZK0wurVg1dfhSeegLXXTte9Pfxwem7KFDj44HSQ4YEHoGtXOPJI\nGDgQrrlmyZ83YULxas87w5skSVppPXqkSQvTpsF996Vt0vnz4Ywz4Kc/hVNOSadVBw784Xvffx82\n3zydXtXyGd4kSdJKa9Ikrb498ECaj3r44WmVrVEj6NkzvWaXXeCTT6B3b/jnPxe/99//TidVX345\nk9Jzx9OmkiSpRjz1FPz616lx7+jRsNFGafWtQaXGZL/8ZZqT+umnMGBAul5u443T79at4S9/yaz8\novG0qSRJKgk//nG6/q158xTc4LvBDdJq3CuvwPXXw8knw/33w49+BCee6MpbVbnyJkmSaszIkenU\n6fKG1McIu+8O48bBzTen06itWsFnn0H9+sWpNSsru/JmeJMkSZkYOhTOPjsFvvr1Yccd04rdjTfC\n00+naQ1HHJF1lTXP8IbhTZKkvKo8UmvOHDjhBNh6a3joIVhnHRg8ePHrHnssnWrN+wguwxuGN0mS\naotRo9K1c/Xrw9y5MH06rLJK2l7dZhu47Tb4+c+X/N558+DPf07X2V1wQeluvxreMLxJklSbdOyY\nxm89+yz86U/QokU6odq/P7zzTmro27TpD983dmwKfs2aQd++6XYpWtnw1mD5L5EkSSqe/v1h3XXT\nFIdDDoHVV0+B7vTT4V//SqdS99zzh++bOBG22w4OOABuueW74W3hwtS2ZJVVivfvKBRbhUiSpJLS\npk1qN3Liienwwj77wJAhsMcesPPOKby99hrMng2PPJKa/EIKb61awVFHwaOPwqxZiz/zn/9MI7sW\nyfM4roKGtxDCzSGEKSGEMUt5/qgQwmshhNEhhGEhhHaVnvtNCOGNEMKYEMJdIYRakJUlSVJVtW2b\nWo78/vdpxNaGG6bw9uKLaWrDnXfCgw/CDTek10+alMJb8+bQqRM8//zizxoyJM1hfeklePPN9Nlf\nf53Nv2tlFXrl7Rag+zKenwB0jTFuD1wK9AMIIWwInAF0jDG2I23v/qzAtUqSpBLUpg3cc0+6vfPO\nabXtgw9Si5HRo9Pv6dMXr7zB4mvmLr88nVgdNgwuvBD69IGHH4ZvvoHXX8/u37QyCnrNW4xxWAih\n9TKeH17p7nCgZaX79YHVQggLgSbAR4WpUpIk5UXr1qmFSI8eaQXu/fehrCz1hasc3rp2hdNOSyFv\njTVgrbXg4oths83Slmvr1vDqq2mFLm9K6Zq3E4HHAWKMHwF/ByYCk4HPYoxDMqxNkiSVgBDSTNSr\nrkonT1u3hoMOSj3gJk5Mo7YgrdC98066Xm6ttaBLF2jUCM47L10Ld8YZaUxXHpXEadMQwh7ACUDn\nivtrAj2B1sAs4L4QwlExxv5L+4zevXt/e7usrIyysrICVixJkrLSrVv63a4dbLklHHYY/OEPqcnv\nopmqjRvDz36W5qc2apR+AH75S9htt3S92913p95wP/lJOsl62GGFqbe8vJzy8vIa+7yC93mr2DYd\nVHHt2pKebwfcD+wTY3y34rHDgO4xxpMq7h8L7Bxj/NVSPsM+b5Ik1TFnngmbbpp+H3IIvPACTJlS\ntffOmZO2Xw86KF039/XX6SBDMVqJrGyft2Jsm4aKnx8+EUIrUnA7dlFwqzAR2CWE0DiEEIC9gDcL\nXqkkScqNq65K25+QVs7atKn6e5s0SStv660HTz0FW2wB115bmDprWkFX3kII/YEyoDkwBbgEWAWI\nMcZ+IYQbgUOAD0gBb16McaeK915COmE6DxgFnBhjnLeU73HlTZKkOm7hwtTYtzrefRd22SW1E9lh\nh5qt6/scj4XhTZIkrbx774VTT4WLLoLf/Gbx4wsXwoIF0LAh3H57mv6w777pudmz0wSIqogxHbjI\nw7apJElSyTv88HSS9YEH4OOPYa+9UnDbZJN0AGL48BTehlT0v3j8cejQIYWy5Zk9OzUZXrhw5es0\nvEmSJFXYemt46y0YMQKGDoWBA9MhhrPPTu1IXn459Y4DuOuutN06fvzyP/f119NJ2Opu61ZmeJMk\nSaqw/vqpfciizh4XX5wG3O+5J9x8M3z5ZQpvc+akSQ/77QdPPrn8zx09Gtq3r5kaDW+SJEkVQkin\nVu+7D/beO7UP2Wsv6NwZpk5N0xwmTkwnVHfYAY49No3fWp7XXoPtt6+ZGg1vkiRJlbRpk4bc/+Y3\n0KAB7LEHNG0KO+0EPXumCQ1Dh6apDXvvna6Fe+GF9N7PP1/yNXCvvebKmyRJUkG0aQP166et0gkT\noHnz9Pgtt8AJJ6Rr1x58EHbcEdZeG+64IzUJPuWUdCjhhhu++3kLFqRr3totcVzBijO8SZIkVdKm\nDWy1VRqptWhWKqRRXKuvnuapTpqUwhuk+alPPgktWqTr4v74R/j97+Ghh9Lzo0en55o1q5n6SmK2\nqSRJUqno3n3xjNQlad0aWrVK0xkW2X77xde0DRuWtlEHD07brFddBSedVHP1Gd4kSZIqWXVV6NRp\n6c+3br141W1J/vEPmD8/rdrde29albvuupqrz/AmSZK0Ao4/Ph1MWJYGDeDII+GYY+C222CNNWru\n+x2PJUmSVADTp8Mnn8A223z3cWebYniTJEn54WxTSZKkOsTwJkmSlCOGN0mSpBwxvEmSJOWI4U2S\nJClHDG+SJEk5YniTJEnKEcObJElSjhjeJEmScsTwJkmSlCOGN0mSpBwxvEmSJOWI4U2SJClHDG+S\nJEk5YniTJEnKEcObJElSjhjeJEmScsTwJkmSlCOGN0mSpBwxvEmSJOWI4U2SJClHDG+SJEk5YniT\nJEnKEcObJElSjhjeJEmScsTwJkmSlCOGN0mSpBwxvEmSJOWI4U2SJClHDG+SJEk5YniTJEnKEcOb\nJElSjhjeJEmScsTwJkmSlCOGN0mSpBwxvEmSJOWI4U2SJClHDG+SJEk5YniTJEnKEcObJElSjhje\nJEmScsTwJkmSlCOGN0mSpBwpaHgLIdwcQpgSQhizlOePCiG8FkIYHUIYFkJoV+m5ZiGEe0MIb4YQ\nxoYQdi5krcpGeXl51iVoJfj3yy//dvnm369uK/TK2y1A92U8PwHoGmPcHrgU6FfpuWuAx2KMbYH2\nwJsFq1KZ8b+A8s2/X375t8s3/351W4NCfniMcVgIofUynh9e6e5woCVACGF1oEuM8fiK180HPi9g\nqZIkSblQSte8nQg8XnF7U2BaCOGWEMKrIYR+IYRVM6xNkiSpJIQYY2G/IK28DYoxtlvGa/YA+gKd\nY4wzQwg7kFbido0xjgwhXA3MijFespT3F/YfIUmSVINijKG67y3otmlVVBxS6AfsE2OcWfHwh8Ck\nGOPIivv3Aect7TNW5v8AkiRJeVKMbdNQ8fPDJ0JoBdwPHBtjfHfR4zHGKcCkEMKWFQ/tBYwrdKGS\nJEmlrqDbpiGE/kAZ0ByYAlwCrALEGGO/EMKNwCHAB6SANy/GuFPFe9sDNwENSadST4gxzipYsZIk\nSTlQ8GveJEmSVHNK6bTpCgsh7BNCeCuE8HYIYanXxCk7S2rUHEJYK4QwOITwvxDCkyGEZpWeuzaE\nML6icfP22VQtgBDCRiGEoSGEcSGE10MIv6543L9fDoQQGoUQXgohjKr4+11S8fjGIYThFX+/u0MI\nDSoeXyWEcE/F3+/FistalKEQQr2KjgsPV9z3b5cTIYT3K4YQjAohvFzxWI39d2duw1sIoR7phGp3\nYBvgyBBCm2yr0hIsqVHz+cCQGONWwFDgAoAQwr7AZjHGLYBfAtcXs1D9wHzgtzHGrYFdgdMr/jPm\n3y8HYoxfA3vEGDsA2wP7/n97dx9jR1WHcfz7AJECWkClmFBoMZKAWEM1QNNWRRSCL6FNsIKCFgMm\nRmJqohipxpgYQ0WNNGpMTDRgMahAS4E/oDVUGirShm2hIhBfUqHqtka7sYCUun38Y84ts7f39kU3\nOzvd55Ns7sy5Z86cu7/s7O/OnJlTZqr5BvDtEr8h4JqyyTXAP0v8bgZuaqDbMdIiRo73TuzaYw9w\nge2ZneFgjOKxs7XJG3Ae8Hvbf7a9G/gZMK/hPkUX2w8DO7qK5wG3luVbeSVu84CflO0eBY6XdPJY\n9DP2ZXvQ9qay/DzVLCdTSfxaw/aLZfFoqqcLGHg31Y1iUMVvflmux/VOqhvFoiGSpgLvpxr73XEh\niV1biH1zrFE7drY5eTsFeK62vrWUxfg3pdxRjO1BYEop747pX0hMxwVJ06nO3vwGODnxa4dy2W0j\nMAisBv4IDNneU6rUj5t742d7GBiS9Nox7nK84jvA9VQJN5JeB+xI7FrDwAOSNki6tpSN2rGz8ee8\n/R96PX4kd1+0W2I6Dkl6NdW3+UW2n9/PQ7ETv3Gm/KOfKWkysAI4q1e18todP5H4NULSB4BttjdJ\nuqBTzL4xSuzGr9m2ByWdBKyS9Az9Y3LIx842n3nbCtQHZU4F/tpQX+LQbOucEpb0BmB7Kd8KnFqr\nl5g2rAyIvhNYZntlKU78Wsb2v4CHgFnACWXMMIyM0d74SToSmFx7cHqMrTnApZL+BNxOdbn0ZqrL\naQiM6CwAAASXSURBVIldC5Qza9j+O3A31VCvUTt2tjl52wC8SdI0Sa8CrgDuabhP0Vv3N8Z7gKvL\n8tXAylr5xwEkzaK6vLNtbLoYffwY+J3tpbWyxK8FJL2+czdbmRv6vVSD39cAC0q1hYyM38KyvIBq\nQHU0wPZi26fZfiPV/7YHbV9FYtcKko4tVyyQdBxwMbCZUTx2tvo5b5IuAZZSJaE/sr2k4S5Flz4P\nar4buIPqm8azwALbQ6X+94BLgBeoHsw80EC3A5A0B1hLddBx+VkMrAd+QeI3rkmaQTUo+ojy83Pb\nX5d0OtUNXicCG4GrbO+WdDSwDJgJ/AO4wvaWRjofe0l6F/A525cmdu1Q4rSC6ph5FPBT20vKOMRR\nOXa2OnmLiIiImGjafNk0IiIiYsJJ8hYRERHRIkneIiIiIlokyVtEREREiyR5i4iIiGiRJG8RERER\nLZLkLSLGnKSd5XWapI+Mcts3dK0/PJrtjzZJCyV9t+l+RER7JHmLiCZ0HjB5OvDRQ9mwNj1QP4tH\n7MieeyjtN+R/fuDmQfw+IuIwkz/6iGjSjcBcSQOSFkk6QtJNkh6VtEnSJ6F6yryktZJWUk3xhKQV\nkjZI2izp2lJ2I3BMaW9ZKdvZ2Zmkb5b6j0v6cK3tNZLukPRUZ7tupc6S0renywwU+5w5k3SvpHd2\n9l0+z28lrZJ0bmnnD5I+WGv+tFL+tKSv1Nq6suxvQNIPJKnW7rckbaSarzQiJpCjmu5ARExoX6RM\n/QNQkrUh2+eXOYvXSVpV6s4Ezrb9bFn/hO0hSZOADZLusn2DpOtsv622D5e2LwPeanuGpCllm4dK\nnXOANwODZZ+zbf+6R3+PLH17H/BV4KL6Pno4Dvil7S9IWg58DXgP8BaqqavuK/XOBc4GXir9ug94\nEbgcmG17WNL3gSuB20q7j9j+fN/fbEQctpK8RcR4cjEwQ1Jn8u3JwBnAbmB9LXED+Kyk+WV5aqm3\nfj9tzwFuB7C9XdKvqJKmnaXtvwFI2gRMB3olb8vL62PAtIP4PLtsd5LPzcBLtvdI2ty1/eraHId3\nAXOBYeDtVMmcgElUySXlveVExISU5C0ixhMBn7G9ekRhNTn3C13rFwLn294laQ1VctNpo1/b/dZ3\n1ZaH6X9s3NWjzn8YOQRlUm15d215T2d725ZU30f9zJ1q67fY/lKPfvzbmZg6YsLKmLeIaEIncdoJ\nvKZW/gDw6U5iI+kMScf22P54YEdJ3M5k5Livl7sSo86+1gKXl3F1JwHvYP9n6g72M2wBzlHlVOC8\nHnX2tz3ARZJOkHQMMB9YBzwIfKj0FUknlvYP1G5EHOZy5i0imtA5a/QEMFwG3t9ie6mk6cBAuVS4\nnSqZ6XY/8ClJTwLPAI/U3vsh8ISkx2x/rLMv2yskzQIepzoLdn25fHpWn7716/OIddvrJG0BngSe\norqkeqC2ut9bT3UZ9BRgme0BAElfBlaVO0pfBq4DnjtAuxFxmFPOvEdERES0Ry6bRkRERLRIkreI\niIiIFknyFhEREdEiSd4iIiIiWiTJW0RERESLJHmLiIiIaJEkbxEREREt8l9AhRUFnpLpyQAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1bc9b69ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A useful debugging strategy is to plot the loss as a function of\n",
    "# iteration number:\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the LinearSVM.predict function \n",
    "y_train_pred = sm.predict(X_train)\n",
    "y_test_pred = sm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.20      0.26        25\n",
      "          1       0.14      0.07      0.10        14\n",
      "          2       0.07      0.03      0.05        30\n",
      "          3       0.75      0.90      0.82       181\n",
      "\n",
      "avg / total       0.60      0.68      0.63       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        25\n",
      "          1       0.00      0.00      0.00        14\n",
      "          2       0.00      0.00      0.00        30\n",
      "          3       0.72      1.00      0.84       181\n",
      "\n",
      "avg / total       0.52      0.72      0.61       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare result with the most common dummy classifier\n",
    "print classification_report(y_test, [3]*len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352278, 2)\n",
      "                                                   Reviews_Summary  Prediction\n",
      "ID                                                                            \n",
      "230872  Babies love these                                           3         \n",
      "344823  Salmon Trout                                                0         \n",
      "211754  disappointment                                              1         \n",
      "259421  Doesn't taste like Cinnabon; tastes like Waffle Crisp       2         \n",
      "253418  Delicious San Daniele prosciutto and good customer service  3         \n",
      "                             Reviews_Summary  Prediction\n",
      "ID                                                      \n",
      "110273  We enjoy this coffee                  3         \n",
      "259187  Satisfied                             2         \n",
      "365859  quite good                            3         \n",
      "131937  Great yummy treat for my little ones  3         \n",
      "121963  Disappointed                          1         \n"
     ]
    }
   ],
   "source": [
    "data = pandas.read_csv(\"kaggle_data/train.csv\", index_col=0, na_values=\"NaN\")\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = data[\"Reviews_Summary\"].values[:1000]\n",
    "score = data[\"Prediction\"].values[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vectorizer = HashingVectorizer(n_features=3000)\n",
    "\n",
    "corpus_hashed = hash_vectorizer.transform(corpus)\n",
    "\n",
    "# print(corpus_hashed)\n",
    "\n",
    "mean_matrix_hash = corpus_hashed.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2201)\t-0.390666501164\n",
      "  (0, 2170)\t0.779067464351\n",
      "  (0, 1134)\t0.490340260287\n",
      "  (1, 1857)\t-0.707106781187\n",
      "  (1, 1353)\t-0.707106781187\n",
      "  (2, 1544)\t1.0\n",
      "  (3, 2437)\t0.400179329608\n",
      "  (3, 1855)\t-0.511667069701\n",
      "  (3, 1706)\t0.251870403554\n",
      "  (3, 1534)\t-0.281490746435\n",
      "  (3, 1480)\t-0.400179329608\n",
      "  (3, 1473)\t-0.400179329608\n",
      "  (3, 1465)\t-0.339250028345\n",
      "  (4, 2860)\t-0.398862124748\n",
      "  (4, 2381)\t-0.42260974453\n",
      "  (4, 2369)\t0.241570983252\n",
      "  (4, 1729)\t0.196491295799\n",
      "  (4, 845)\t-0.221485108061\n",
      "  (4, 448)\t-0.398862124748\n",
      "  (4, 442)\t-0.42260974453\n",
      "  (4, 72)\t0.42260974453\n",
      "  (5, 1591)\t0.561683898009\n",
      "  (5, 1490)\t0.41152000634\n",
      "  (5, 719)\t-0.523493979178\n",
      "  (5, 93)\t-0.491036186919\n",
      "  :\t:\n",
      "  (995, 179)\t-0.436247113522\n",
      "  (996, 2462)\t0.223607164312\n",
      "  (996, 2344)\t0.37541247004\n",
      "  (996, 1591)\t0.286718110855\n",
      "  (996, 1563)\t-0.184805274749\n",
      "  (996, 1212)\t0.327739843415\n",
      "  (996, 1092)\t-0.327739843415\n",
      "  (996, 985)\t-0.339349520165\n",
      "  (996, 861)\t0.354316996698\n",
      "  (996, 275)\t0.310233920079\n",
      "  (996, 49)\t-0.37541247004\n",
      "  (997, 2763)\t-0.420486443733\n",
      "  (997, 2531)\t-0.378820253791\n",
      "  (997, 2201)\t0.248724097697\n",
      "  (997, 1490)\t0.277544209108\n",
      "  (997, 1124)\t-0.367336841689\n",
      "  (997, 918)\t0.277544209108\n",
      "  (997, 897)\t-0.468133855274\n",
      "  (997, 93)\t-0.33117284225\n",
      "  (998, 2388)\t0.28699434447\n",
      "  (998, 2027)\t0.629513686819\n",
      "  (998, 1000)\t-0.602921027075\n",
      "  (998, 691)\t0.397282015024\n",
      "  (999, 2704)\t-0.765929143778\n",
      "  (999, 1729)\t0.642924993067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "TFIDFtransformer = TfidfTransformer()\n",
    "\n",
    "corpus_TFIDF = TFIDFtransformer.fit_transform(corpus_hashed)\n",
    "\n",
    "print(corpus_TFIDF)\n",
    "corpus_TFIDF\n",
    "\n",
    "\n",
    "mean_matrix_TFIDF = corpus_TFIDF.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(1000, 3000)\n"
     ]
    }
   ],
   "source": [
    "corpus_np = corpus_TFIDF.toarray()\n",
    "\n",
    "print(corpus_np)\n",
    "print(corpus_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CVX_train = corpus_np\n",
    "CVy_train = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CVX_train = CVX_train.transpose()\n",
    "CVy_train = CVy_train.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def accuracy(y_true, y_predict):\n",
    "    return metrics.accuracy_score(y_true, y_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "from sklearn import cross_validation\n",
    "from datetime import datetime\n",
    "\n",
    "def my_cross_validation(X, y, predictor, batch_size, q_fold = 5, r_fold = 5):\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    total_size = X.shape[1]\n",
    "    \n",
    "    seed = datetime.now().microsecond + datetime.now().second * 1000000\n",
    "    \n",
    "    shuffled_split = cross_validation.ShuffleSplit(total_size, n_iter=r_fold, test_size=1.0/q_fold, random_state=seed)\n",
    "    \n",
    "    for train_index, test_index in shuffled_split:\n",
    "#         print(train_index, test_index)\n",
    "#         print(X.shape)\n",
    "        X_train = X[:, train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[:, test_index]\n",
    "        y_test = y[test_index]\n",
    "        \n",
    "        predictor.train(X_train, y_train, learning_rate=5e-2, reg=0.01,\n",
    "                      num_iters=500, verbose=True, batch_size=20000)\n",
    "        \n",
    "        y_predicted = predictor.predict(X_test)\n",
    "        \n",
    "#         predictor = predictor.fit(X_train, y_train)\n",
    "#         predictor = predictor.calc_dist(X_test, metric)\n",
    "#         y_predicted = predictor.predict_labels(X_test)\n",
    "        \n",
    "        scores.append(accuracy(y_test, y_predicted))\n",
    "    \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers import Softmax\n",
    "\n",
    "my_cross_validation(CVX_train, CVy_train, Softmax(), 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job # 5 in a separate thread.\n",
      "Starting job # 6 in a separate thread.\n",
      "Starting job # 7 in a separate thread.\n",
      "Starting job # 8 in a separate thread.\n"
     ]
    }
   ],
   "source": [
    "# for chunk in get_chunks(urls, 3):\n",
    "#     %job [fetch_url(_) for _ in log_progress(chunk, every=1)]\n",
    "\n",
    "import sys\n",
    "\n",
    "for batch_size in [10, 15, 20, 25]:#[10000, 15000, 20000, 25000]:\n",
    "    %job [sys.stderr.print(my_cross_validation(CVX_train, CVy_train, Softmax(), _)) for _ in log_progress(batch, every=1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for job in jobs.running:\n",
    "    kill_thread(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kaggle In Class - 50 Баллов\n",
    "\n",
    "Используйте полученные модели для решения контеста. Выберете одну из моделей, реализуйте настройку гиперпараметров и пайплайн для предсказания классов тестовой выборки для сабмита в систему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "Финальные результаты для контеста я получал на другом, более мощном компе (здесь датасет не влезал в оперативку, начинался лютый swap, трешинг и оно могло продолжаться вечно).\n",
    "\n",
    "Поэтому в этом ноутбуке эта часть не исполнялась.\n",
    "\n",
    "Однако, в архиве лежит та самая посылка, кажется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = data[\"Reviews_Summary\"].values[:150000]\n",
    "score = data[\"Prediction\"].values[:150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vectorizer = HashingVectorizer(n_features=3000)\n",
    "\n",
    "corpus_hashed = hash_vectorizer.transform(corpus)\n",
    "\n",
    "# print(corpus_hashed)\n",
    "\n",
    "mean_matrix_hash = corpus_hashed.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2201)\t-0.388087041871\n",
      "  (0, 2170)\t0.797261449037\n",
      "  (0, 1134)\t0.46234470886\n",
      "  (1, 1857)\t-0.585449721059\n",
      "  (1, 1353)\t-0.810708717181\n",
      "  (2, 1544)\t1.0\n",
      "  (3, 2437)\t0.406636837688\n",
      "  (3, 1855)\t-0.472879818054\n",
      "  (3, 1706)\t0.223009443256\n",
      "  (3, 1534)\t-0.276326371382\n",
      "  (3, 1480)\t-0.427133236033\n",
      "  (3, 1473)\t-0.429236822175\n",
      "  (3, 1465)\t-0.343881714801\n",
      "  (4, 2860)\t-0.415063911996\n",
      "  (4, 2381)\t-0.479051022982\n",
      "  (4, 2369)\t0.208293833248\n",
      "  (4, 1729)\t0.166347090244\n",
      "  (4, 845)\t-0.181486200877\n",
      "  (4, 448)\t-0.315606706645\n",
      "  (4, 442)\t-0.35157973944\n",
      "  (4, 72)\t0.520597006681\n",
      "  (5, 1591)\t0.528041718732\n",
      "  (5, 1490)\t0.405698776136\n",
      "  (5, 719)\t-0.567388184332\n",
      "  (5, 93)\t-0.484407983627\n",
      "  :\t:\n",
      "  (149994, 811)\t0.36106911323\n",
      "  (149994, 582)\t0.246338063177\n",
      "  (149994, 522)\t-0.257311653332\n",
      "  (149994, 312)\t0.514746539396\n",
      "  (149995, 2294)\t1.0\n",
      "  (149996, 2388)\t0.341739803231\n",
      "  (149996, 1801)\t0.778369270629\n",
      "  (149996, 972)\t0.526645217797\n",
      "  (149997, 2958)\t-0.338519179805\n",
      "  (149997, 1298)\t-0.494010033191\n",
      "  (149997, 735)\t0.666610424603\n",
      "  (149997, 277)\t0.443834872246\n",
      "  (149998, 2729)\t0.750388410987\n",
      "  (149998, 1209)\t0.660997150264\n",
      "  (149999, 2996)\t0.301877382692\n",
      "  (149999, 2958)\t-0.166352860126\n",
      "  (149999, 2284)\t-0.276875393828\n",
      "  (149999, 1682)\t0.315189493813\n",
      "  (149999, 1568)\t0.335193964914\n",
      "  (149999, 1298)\t-0.242763148605\n",
      "  (149999, 1209)\t0.271153695427\n",
      "  (149999, 1118)\t-0.406101180722\n",
      "  (149999, 869)\t0.316097711125\n",
      "  (149999, 534)\t-0.384672288263\n",
      "  (149999, 277)\t0.218106402315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "TFIDFtransformer = TfidfTransformer()\n",
    "\n",
    "corpus_TFIDF = TFIDFtransformer.fit_transform(corpus_hashed)\n",
    "\n",
    "print(corpus_TFIDF)\n",
    "corpus_TFIDF\n",
    "\n",
    "\n",
    "mean_matrix_TFIDF = corpus_TFIDF.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(150000, 3000)\n"
     ]
    }
   ],
   "source": [
    "corpus_np = corpus_TFIDF.toarray()\n",
    "\n",
    "print(corpus_np)\n",
    "print(corpus_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KX_train = corpus_np[:10]\n",
    "Ky_train = score[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KX_train = KX_train.transpose()\n",
    "Ky_train = Ky_train.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 500: loss 1.386600\n"
     ]
    }
   ],
   "source": [
    "from cs231n.classifiers import Softmax\n",
    "import time\n",
    "sm = Softmax()\n",
    "tic = time.time()\n",
    "loss_hist = sm.train(KX_train, Ky_train, learning_rate=5e-2, reg=0.01,\n",
    "                      num_iters=500, verbose=True, batch_size=20000)\n",
    "\n",
    "toc = time.time()\n",
    "print 'That took %fs' % (toc - tic)\n",
    "print 'Current loss is %f' % loss_hist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test = pandas.read_csv(\"kaggle_data/test.csv\", na_values=\"NaN\")\n",
    "\n",
    "print(data_test.shape)\n",
    "print(data_test.head())\n",
    "print(data_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KX_test = data_test[\"Reviews_Summary\"]\n",
    "KIDs = data_test[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hash_vectorizer = HashingVectorizer(n_features=3000)\n",
    "\n",
    "KX_test_hashed = hash_vectorizer.transform(KX_test)\n",
    "\n",
    "# print(corpus_hashed)\n",
    "\n",
    "mean_matrix_hash = KX_test_hashed.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "TFIDFtransformer = TfidfTransformer()\n",
    "\n",
    "KX_test_TFIDF = TFIDFtransformer.fit_transform(KX_test_hashed)\n",
    "\n",
    "print(KX_test_TFIDF)\n",
    "KX_test_TFIDF\n",
    "\n",
    "\n",
    "mean_matrix_TFIDF = KX_test_TFIDF.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KX_test = KX_test_TFIDF.toarray()\n",
    "\n",
    "print(KX_test)\n",
    "print(KX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KX_test = KX_test.transpose()\n",
    "\n",
    "print(KX_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ky_test_pred = sm.predict(KX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Ky_test_pred)\n",
    "print(Ky_test_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(numpy.unique(Ky_test_pred, return_counts = True)) # no NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "ans = open(\"kaggle_prediction.csv\", \"w\")\n",
    "\n",
    "ans.write(\"ID,class_0,class_1,class_2,class_3\\n\")\n",
    "\n",
    "for index in range(KIDs.size):\n",
    "    ID = KIDs[index]\n",
    "    class_0 = float(Ky_test_pred[index] == 0)\n",
    "    class_1 = float(Ky_test_pred[index] == 1)\n",
    "    class_2 = float(Ky_test_pred[index] == 2)\n",
    "    class_3 = float(Ky_test_pred[index] == 3)\n",
    "    ans.write(\"%d,%.1f,%.1f,%.1f,%.1f\\n\" % (ID, class_0, class_1, class_2, class_3))\n",
    "    \n",
    "ans.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
